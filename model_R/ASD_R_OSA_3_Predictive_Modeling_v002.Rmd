---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.3.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="https://github.com/dd-consulting">
         <img src="../reference/GZ_logo.png" width="60" align="right">
    </a>
    <h1>
        One-Stop Analytics: Predictive Modeling (Non-Linear Models)
    </h1>
</div>



# Case Study of Autism Spectrum Disorder (ASD) with R

---

<img src="../reference/CDC_ASD/CDC_ASD_01.jpg" align="left">

<img src="../reference/CDC_ASD/CDC_ASD_02.png" width="700" align="center">



## <span style="color:blue">[ United States ]</span> 

## Centers for Disease Control and Prevention (CDC) - Autism Spectrum Disorder (ASD)

Autism spectrum disorder (ASD) is a developmental disability that can cause significant social, communication and behavioral challenges. CDC is committed to continuing to provide essential data on ASD, search for factors that put children at risk for ASD and possible causes, and develop resources that help identify children with ASD as early as possible.

https://www.cdc.gov/ncbddd/autism/data/index.html



## <span style="color:blue">[ Singapore ]</span> 

## TODAY Online - More preschoolers diagnosed with developmental issues

Doctors cited better awareness among parents and preschool teachers, leading to early referrals for diagnosis.

https://www.gov.sg/news/content/today-online-more-preschoolers-diagnosed-with-developmental-issues

<img src="../reference/SG_ASD/SG_ASD_01.png" width="650" align="left">




<img src="../reference/SG_ASD/SG_ASD_04.png" align="left"> 

https://www.pathlight.org.sg/


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="60" align="right">
    </a>
</div>



# Workshop Objective: 

## Use R to predict Autism Spectrum Disorder (ASD) prevalence. 

https://www.cdc.gov/ncbddd/autism/data/index.html

* ## R Rattle Tool

* ## R Rattle Tool: Import Data

* ## R Rattle Tool: EDA Explore & Test

* ## R Rattle Tool: Process & Transform Data

* ## R Rattle Tool: Train Model

    * ### Non-Linear Model: Decision Tree (DT)

    * ### Non-Linear Model: Random Forest (RF)

    * ### Non-Linear Model: Adaptive Boosting (AdaBoost)

    * ### Non-Linear Model: Neural Network (NN)

    * ### Non-Linear Model: Support Vector Machines (SVM)

* ## R Rattle Tool: Evaluate Model

* ## R Rattle Tool: Improve Model

* ## R Rattle Tool: Save Model & Log

* ## R Rattle Tool: Miscellaneous

* ## Workshop Submission

* ## Appendices


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>



```{r}
library("repr") # Show graphs in-line notebook
```

**Obtain current R <span style="color:blue">working directory</span>**

```{r}
getwd()
```

**Set new R working directory**

```{r}
# setwd("/media/sf_vm_shared_folder/git/DDC/DDC-ASD/model_R")
# setwd('~/Desktop/admin-desktop/vm_shared_folder/git/DDC-ASD/model_R')
getwd()
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">R Rattle Tool</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool
    </h3>
</div>


```{r}
if(!require(rattle)){install.packages("rattle")}
library('rattle')
```

<img src="../reference/R rattle/000 Rattle/a001.png" align="left"> 


```{r}
#=======================================================================

# Rattle is Copyright (c) 2006-2018 Togaware Pty Ltd.
# It is free (as in libre) open source software.
# It is licensed under the GNU General Public License,
# Version 2. Rattle comes with ABSOLUTELY NO WARRANTY.
# Rattle was written by Graham Williams with contributions
# from others as acknowledged in 'library(help=rattle)'.
# Visit https://rattle.togaware.com/ for details.

#=======================================================================
# Rattle timestamp: 2019-12-23 09:42:23 x86_64-pc-linux-gnu 

# Rattle version 5.3.0 user 'iss-user'

# This log captures interactions with Rattle as an R script. 

# For repeatability, export this activity log to a 
# file, like 'model.R' using the Export button or 
# through the Tools menu. Th script can then serve as a 
# starting point for developing your own scripts. 
# After xporting to a file called 'model.R', for exmample, 
# you can type into a new R Console the command 
# "source('model.R')" and so repeat all actions. Generally, 
# you will want to edit the file to suit your own needs. 
# You can also edit this log in place to record additional 
# information before exporting the script. 
 
# Note that saving/loading projects retains this log.

# We begin most scripts by loading the required packages.
# Here are some initial packages to load and others will be
# identified as we proceed through the script. When writing
# our own scripts we often collect together the library
# commands at the beginning of the script here.

library(rattle)   # Access the weather dataset and utilities.
library(magrittr) # Utilise %>% and %<>% pipeline operators.

# This log generally records the process of building a model. 
# However, with very little effort the log can also be used 
# to score a new dataset. The logical variable 'building' 
# is used to toggle between generating transformations, 
# when building a model and using the transformations, 
# when scoring a dataset.

building <- TRUE
scoring  <- ! building

# A pre-defined value is used to reset the random seed 
# so that results are repeatable.

crv$seed <- 42 
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">R Rattle Tool: Import Data</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: Import Data
    </h3>
</div>



**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


<img src="../reference/R rattle/010 Import Data/a001.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:01:39 x86_64-pc-linux-gnu 

# Load a dataset from file.

fname         <- "../dataset/ADV_ASD_State_R.csv" 
crs$dataset <- read.csv(fname,
			na.strings=c(".", "NA", "", "?"),
			strip.white=TRUE, encoding="UTF-8")

#=======================================================================
# Rattle timestamp: 2019-12-23 10:01:40 x86_64-pc-linux-gnu 

# Action the user selections from the Data tab. 

# Build the train/validate/test datasets.

# nobs=1692 train=1184 validate=254 test=254

set.seed(crv$seed)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.7*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  sample(0.15*crs$nobs) ->
crs$validate

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  setdiff(crs$validate) ->
crs$test

# The following variable selections have been noted.

crs$input     <- c("State", "Denominator", "Prevalence",
                   "Lower.CI", "Upper.CI", "Year", "Source_Full1",
                   "State_Full1", "State_Full2", "Numerator_ASD",
                   "Numerator_NonASD", "Proportion",
                   "Chi_Wilson_Corrected_Lower.CI",
                   "Chi_Wilson_Corrected_Upper.CI",
                   "Male.Prevalence", "Male.Lower.CI",
                   "Male.Upper.CI", "Female.Prevalence",
                   "Female.Lower.CI", "Female.Upper.CI",
                   "Non.hispanic.white.Prevalence",
                   "Non.hispanic.white.Lower.CI",
                   "Non.hispanic.white.Upper.CI",
                   "Non.hispanic.black.Prevalence",
                   "Non.hispanic.black.Lower.CI",
                   "Non.hispanic.black.Upper.CI",
                   "Hispanic.Prevalence", "Hispanic.Lower.CI",
                   "Hispanic.Upper.CI",
                   "Asian.or.Pacific.Islander.Prevalence",
                   "Asian.or.Pacific.Islander.Lower.CI",
                   "Asian.or.Pacific.Islander.Upper.CI", "Source_UC",
                   "Source_Full3", "Prevalence_Risk2",
                   "Prevalence_Risk4", "Year_Factor")

crs$numeric   <- c("Denominator", "Prevalence", "Lower.CI",
                   "Upper.CI", "Year", "Numerator_ASD",
                   "Numerator_NonASD", "Proportion",
                   "Chi_Wilson_Corrected_Lower.CI",
                   "Chi_Wilson_Corrected_Upper.CI",
                   "Male.Prevalence", "Male.Lower.CI",
                   "Male.Upper.CI", "Female.Prevalence",
                   "Female.Lower.CI", "Female.Upper.CI",
                   "Non.hispanic.white.Prevalence",
                   "Non.hispanic.white.Lower.CI",
                   "Non.hispanic.white.Upper.CI",
                   "Non.hispanic.black.Prevalence",
                   "Non.hispanic.black.Lower.CI",
                   "Non.hispanic.black.Upper.CI",
                   "Hispanic.Prevalence", "Hispanic.Lower.CI",
                   "Hispanic.Upper.CI",
                   "Asian.or.Pacific.Islander.Prevalence",
                   "Asian.or.Pacific.Islander.Lower.CI",
                   "Asian.or.Pacific.Islander.Upper.CI",
                   "Year_Factor")

crs$categoric <- c("State", "Source_Full1", "State_Full1",
                   "State_Full2", "Source_UC", "Source_Full3",
                   "Prevalence_Risk2", "Prevalence_Risk4")

crs$target    <- "Source"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- NULL
crs$weights   <- NULL
```

<img src="../reference/R rattle/010 Import Data/a002.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:05:28 x86_64-pc-linux-gnu 

# Action the user selections from the Data tab. 

# Build the train/validate/test datasets.

# nobs=1692 train=1184 validate=254 test=254

set.seed(88)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.7*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  sample(0.15*crs$nobs) ->
crs$validate

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  setdiff(crs$validate) ->
crs$test

# The following variable selections have been noted.

crs$input     <- c("State", "Denominator", "Prevalence",
                   "Lower.CI", "Upper.CI", "Year", "Source",
                   "Source_Full1", "State_Full1", "State_Full2",
                   "Numerator_ASD", "Numerator_NonASD", "Proportion",
                   "Chi_Wilson_Corrected_Lower.CI",
                   "Chi_Wilson_Corrected_Upper.CI",
                   "Male.Prevalence", "Male.Lower.CI",
                   "Male.Upper.CI", "Female.Prevalence",
                   "Female.Lower.CI", "Female.Upper.CI",
                   "Non.hispanic.white.Prevalence",
                   "Non.hispanic.white.Lower.CI",
                   "Non.hispanic.white.Upper.CI",
                   "Non.hispanic.black.Prevalence",
                   "Non.hispanic.black.Lower.CI",
                   "Non.hispanic.black.Upper.CI",
                   "Hispanic.Prevalence", "Hispanic.Lower.CI",
                   "Hispanic.Upper.CI",
                   "Asian.or.Pacific.Islander.Prevalence",
                   "Asian.or.Pacific.Islander.Lower.CI",
                   "Asian.or.Pacific.Islander.Upper.CI", "Source_UC",
                   "Source_Full3", "Prevalence_Risk2", "Year_Factor")

crs$numeric   <- c("Denominator", "Prevalence", "Lower.CI",
                   "Upper.CI", "Year", "Numerator_ASD",
                   "Numerator_NonASD", "Proportion",
                   "Chi_Wilson_Corrected_Lower.CI",
                   "Chi_Wilson_Corrected_Upper.CI",
                   "Male.Prevalence", "Male.Lower.CI",
                   "Male.Upper.CI", "Female.Prevalence",
                   "Female.Lower.CI", "Female.Upper.CI",
                   "Non.hispanic.white.Prevalence",
                   "Non.hispanic.white.Lower.CI",
                   "Non.hispanic.white.Upper.CI",
                   "Non.hispanic.black.Prevalence",
                   "Non.hispanic.black.Lower.CI",
                   "Non.hispanic.black.Upper.CI",
                   "Hispanic.Prevalence", "Hispanic.Lower.CI",
                   "Hispanic.Upper.CI",
                   "Asian.or.Pacific.Islander.Prevalence",
                   "Asian.or.Pacific.Islander.Lower.CI",
                   "Asian.or.Pacific.Islander.Upper.CI",
                   "Year_Factor")

crs$categoric <- c("State", "Source", "Source_Full1",
                   "State_Full1", "State_Full2", "Source_UC",
                   "Source_Full3", "Prevalence_Risk2")

crs$target    <- "Prevalence_Risk4"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- NULL
crs$weights   <- NULL
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">R Rattle Tool: EDA Explore & Test</span>


```{r}
if(!require(Hmisc)){install.packages("Hmisc")}
library('Hmisc')
```

```{r}
if(!require(fBasics)){install.packages("fBasics")}
library('fBasics')
```

```{r}
if(!require(mice)){install.packages("mice")}
library('mice')
```

```{r}
if(!require(descr)){install.packages("descr")}
library('descr')
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: EDA Explore & Test: Summary
    </h3>
</div>



<img src="../reference/R rattle/020 EDA Explore n Test/a003.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:12:32 x86_64-pc-linux-gnu 

# The 'Hmisc' package provides the 'contents' function.

library(Hmisc, quietly=TRUE)

# Obtain a summary of the dataset.

contents(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)])
summary(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)])

# The 'Hmisc' package provides the 'describe' function.

library(Hmisc, quietly=TRUE)

# Generate a description of the dataset.

describe(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)])

# The 'basicStats' package provides the 'fBasics' function.

library(fBasics, quietly=TRUE)

# Generate a description of the numeric data.

lapply(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)][,c(2:6, 11:33, 37)], basicStats)

# The 'kurtosis' package provides the 'fBasics' function.

library(fBasics, quietly=TRUE)

# Summarise the kurtosis of the numeric data.

kurtosis(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)][,c(2:6, 11:33, 37)], na.rm=TRUE)

# The 'skewness' package provides the 'fBasics' function.

library(fBasics, quietly=TRUE)

# Summarise the skewness of the numeric data.

skewness(crs$dataset[crs$train, c(crs$input, crs$risk, crs$target)][,c(2:6, 11:33, 37)], na.rm=TRUE)

# The 'mice' package provides the 'md.pattern' function.

library(mice, quietly=TRUE)

# Generate a summary of the missing values in the dataset.

md.pattern(crs$dataset[,c(crs$input, crs$target)])

# The 'CrossTable' package provides the 'descr' function.

library(descr, quietly=TRUE)

# Generate cross tabulations for categoric data.

for (i in c(1, 7:10, 34:36)) 
{ 
  cat(sprintf('CrossTab of %s by target variable %s\n\n', names(crs$dataset)[i], crs$target)) 
  print(CrossTable(crs$dataset[[i]], crs$dataset[[crs$target]], expected=TRUE, format='SAS')) 
  cat(paste(rep('=', 70), collapse=''), '

') 
}
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: EDA Explore & Test: Distribution
    </h3>
</div>



<img src="../reference/R rattle/020 EDA Explore n Test/a007.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:45:21 x86_64-pc-linux-gnu 

# Display box plots for the selected variables. 

# Use ggplot2 to generate box plot for Denominator

# Generate a box plot.

p01 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  ggplot2::ggplot(ggplot2::aes(y=Denominator)) +
  ggplot2::geom_boxplot(ggplot2::aes(x="All"), notch=TRUE, fill="grey") +
  ggplot2::stat_summary(ggplot2::aes(x="All"), fun.y=mean, geom="point", shape=8) +
  ggplot2::geom_boxplot(ggplot2::aes(x=Prevalence_Risk4, fill=Prevalence_Risk4), notch=TRUE) +
  ggplot2::stat_summary(ggplot2::aes(x=Prevalence_Risk4), fun.y=mean, geom="point", shape=8) +
  ggplot2::xlab("Prevalence_Risk4\n\nRattle 2019-Dec-23 10:45:21 iss-user") +
  ggplot2::ggtitle("Distribution of Denominator (sample)\nby Prevalence_Risk4") +
  ggplot2::theme(legend.position="none")

# Use ggplot2 to generate box plot for Prevalence

# Generate a box plot.

p02 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  ggplot2::ggplot(ggplot2::aes(y=Prevalence)) +
  ggplot2::geom_boxplot(ggplot2::aes(x="All"), notch=TRUE, fill="grey") +
  ggplot2::stat_summary(ggplot2::aes(x="All"), fun.y=mean, geom="point", shape=8) +
  ggplot2::geom_boxplot(ggplot2::aes(x=Prevalence_Risk4, fill=Prevalence_Risk4), notch=TRUE) +
  ggplot2::stat_summary(ggplot2::aes(x=Prevalence_Risk4), fun.y=mean, geom="point", shape=8) +
  ggplot2::xlab("Prevalence_Risk4\n\nRattle 2019-Dec-23 10:45:21 iss-user") +
  ggplot2::ggtitle("Distribution of Prevalence (sample)\nby Prevalence_Risk4") +
  ggplot2::theme(legend.position="none")

# Use ggplot2 to generate box plot for Lower.CI

# Generate a box plot.

p03 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  ggplot2::ggplot(ggplot2::aes(y=Lower.CI)) +
  ggplot2::geom_boxplot(ggplot2::aes(x="All"), notch=TRUE, fill="grey") +
  ggplot2::stat_summary(ggplot2::aes(x="All"), fun.y=mean, geom="point", shape=8) +
  ggplot2::geom_boxplot(ggplot2::aes(x=Prevalence_Risk4, fill=Prevalence_Risk4), notch=TRUE) +
  ggplot2::stat_summary(ggplot2::aes(x=Prevalence_Risk4), fun.y=mean, geom="point", shape=8) +
  ggplot2::xlab("Prevalence_Risk4\n\nRattle 2019-Dec-23 10:45:21 iss-user") +
  ggplot2::ggtitle("Distribution of Lower.CI (sample)\nby Prevalence_Risk4") +
  ggplot2::theme(legend.position="none")

# Use ggplot2 to generate box plot for Upper.CI

# Generate a box plot.

p04 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  ggplot2::ggplot(ggplot2::aes(y=Upper.CI)) +
  ggplot2::geom_boxplot(ggplot2::aes(x="All"), notch=TRUE, fill="grey") +
  ggplot2::stat_summary(ggplot2::aes(x="All"), fun.y=mean, geom="point", shape=8) +
  ggplot2::geom_boxplot(ggplot2::aes(x=Prevalence_Risk4, fill=Prevalence_Risk4), notch=TRUE) +
  ggplot2::stat_summary(ggplot2::aes(x=Prevalence_Risk4), fun.y=mean, geom="point", shape=8) +
  ggplot2::xlab("Prevalence_Risk4\n\nRattle 2019-Dec-23 10:45:22 iss-user") +
  ggplot2::ggtitle("Distribution of Upper.CI (sample)\nby Prevalence_Risk4") +
  ggplot2::theme(legend.position="none")

# Display the plots.

gridExtra::grid.arrange(p01, p02, p03, p04)
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a008.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:43:09 x86_64-pc-linux-gnu 

# Display histogram plots for the selected variables. 

# Use ggplot2 to generate histogram plot for Denominator

# Generate the plot.

p01 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Denominator, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Denominator)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Denominator\n\nRattle 2019-Dec-23 10:43:09 iss-user") +
  ggplot2::ggtitle("Distribution of Denominator (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Use ggplot2 to generate histogram plot for Prevalence

# Generate the plot.

p02 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Prevalence, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Prevalence)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Prevalence\n\nRattle 2019-Dec-23 10:43:09 iss-user") +
  ggplot2::ggtitle("Distribution of Prevalence (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Use ggplot2 to generate histogram plot for Lower.CI

# Generate the plot.

p03 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Lower.CI, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Lower.CI)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Lower.CI\n\nRattle 2019-Dec-23 10:43:09 iss-user") +
  ggplot2::ggtitle("Distribution of Lower.CI (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Use ggplot2 to generate histogram plot for Upper.CI

# Generate the plot.

p04 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Upper.CI, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Upper.CI)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Upper.CI\n\nRattle 2019-Dec-23 10:43:09 iss-user") +
  ggplot2::ggtitle("Distribution of Upper.CI (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Display the plots.

gridExtra::grid.arrange(p01, p02, p03, p04)
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a009.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:48:49 x86_64-pc-linux-gnu 

# Display histogram plots for the selected variables. 

# Use ggplot2 to generate histogram plot for Year

# Generate the plot.

p01 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Year, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Year)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Year\n\nRattle 2019-Dec-23 10:48:49 iss-user") +
  ggplot2::ggtitle("Distribution of Year (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Display the plots.

gridExtra::grid.arrange(p01)
```

---

```{r}
if(!require(GGally)){install.packages("GGally")}
library('GGally')
```

<img src="../reference/R rattle/020 EDA Explore n Test/a010.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 10:54:13 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(2,3,4,5),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a011.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:06:10 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(3,11,13),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a012.png" align="left"> 


```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:07:28 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(3,16,19),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a013.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:11:18 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(3,22,25,28,31),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a014.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:15:09 x86_64-pc-linux-gnu 

# Mosaic Plot 

# Generate the table data for plotting.

ds <- table(crs$dataset[crs$train,]$State, crs$dataset[crs$train,]$Prevalence_Risk4)

# Sort the entries.

ord <- order(apply(ds, 1, sum), decreasing=TRUE)

# Plot the data.

mosaicplot(ds[ord,], main="Mosaic of State (sample)
by Prevalence_Risk4", sub="Rattle 2019-Dec-23 11:15:09 iss-user", color=colorspace::rainbow_hcl(5)[-1], cex=0.7, xlab="State", ylab="Prevalence_Risk4")
```

---

```{r}
if(!require(gplots)){install.packages("gplots")}
library('gplots')
```

<img src="../reference/R rattle/020 EDA Explore n Test/a015.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:16:35 x86_64-pc-linux-gnu 

# The 'gplots' package provides the 'barplot2' function.

library(gplots, quietly=TRUE)

#=======================================================================
# Rattle timestamp: 2019-12-23 11:16:36 x86_64-pc-linux-gnu 

# Bar Plot 

# Generate the summary data for plotting.

ds <- rbind(summary(na.omit(crs$dataset[crs$train,]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="High",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Low",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Medium",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Very High",]$Source)))

# Sort the entries.

ord <- order(ds[1,], decreasing=TRUE)

# Plot the data.

bp <-  barplot2(ds[,ord], beside=TRUE, ylab="Frequency", xlab="Source", ylim=c(0, 715), col=colorspace::rainbow_hcl(5))

# Add the actual frequencies.

text(bp, ds[,ord]+24, ds[,ord])

# Add a legend to the plot.

legend("topright", bty="n", c("All","High","Low","Medium","Very High"),  fill=colorspace::rainbow_hcl(5))

# Add a title to the plot.

title(main="Distribution of Source (sample)\nby Prevalence_Risk4",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a016.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:21:08 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(7,37),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a017.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:25:27 x86_64-pc-linux-gnu 

# Display a pairs plot for the selected variables. 

# Use GGally's ggpairs() to do the hard work.

crs$dataset[crs$train,] %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  GGally::ggpairs(columns=c(3,7,37),
        mapping=ggplot2::aes(colour=Prevalence_Risk4, alpha=0.5),
                diag=list(continuous="density",
                          discrete="bar"),
                upper=list(continuous="cor",
                           combo="box",
                           discrete="ratio"),
                lower=list(continuous="points",
                           combo="denstrip",
                           discrete="facetbar")) +
  ggplot2::theme(panel.grid.major=ggplot2::element_blank())
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: EDA Explore & Test: Correlation
    </h3>
</div>



<img src="../reference/R rattle/020 EDA Explore n Test/a018.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:31:10 x86_64-pc-linux-gnu 

# Generate a correlation plot for the variables. 

# The 'corrplot' package provides the 'corrplot' function.

library(corrplot, quietly=TRUE)

# Correlations work for numeric variables only.

crs$cor <- cor(crs$dataset[crs$train, crs$numeric], use="pairwise", method="pearson")

# Order the correlations by their strength.

crs$ord <- order(crs$cor[1,])
crs$cor <- crs$cor[crs$ord, crs$ord]

# Display the actual correlations.

print(crs$cor)

# Graphically display the correlations.

corrplot(crs$cor, mar=c(0,0,1,0))
title(main="Correlation ADV_ASD_State_R.csv using Pearson",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a019.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:32:46 x86_64-pc-linux-gnu 

# Hierarchical Variable Correlation 

# Generate the correlations (numerics only).

cc <- cor(crs$dataset[crs$train, crs$numeric], use="pairwise", method="pearson")

# Generate hierarchical cluster of variables.

hc <- hclust(dist(cc), method="average")

# Generate the dendrogram.

dn <- as.dendrogram(hc)

# Now draw the dendrogram.

op <- par(mar = c(3, 4, 3, 10.86))
plot(dn, horiz = TRUE, nodePar = list(col = 3:2, cex = c(2.0, 0.75), pch = 21:22, bg=  c("light blue", "pink"), lab.cex = 0.75, lab.col = "tomato"), edgePar = list(col = "gray", lwd = 2), xlab="Height")
title(main="Variable Correlation Clusters
 ADV_ASD_State_R.csv using Pearson",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
par(op)

```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a020.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:33:55 x86_64-pc-linux-gnu 

# Hierarchical Variable Correlation 

# Generate the correlations (numerics only).

cc <- cor(crs$dataset[crs$train, crs$numeric], use="pairwise", method="spearman")

# Generate hierarchical cluster of variables.

hc <- hclust(dist(cc), method="average")

# Generate the dendrogram.

dn <- as.dendrogram(hc)

# Now draw the dendrogram.

op <- par(mar = c(3, 4, 3, 10.86))
plot(dn, horiz = TRUE, nodePar = list(col = 3:2, cex = c(2.0, 0.75), pch = 21:22, bg=  c("light blue", "pink"), lab.cex = 0.75, lab.col = "tomato"), edgePar = list(col = "gray", lwd = 2), xlab="Height")
title(main="Variable Correlation Clusters
 ADV_ASD_State_R.csv using Spearman",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
par(op)

```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a021.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:36:12 x86_64-pc-linux-gnu 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$train, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance ADV_ASD_State_R.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components ADV_ASD_State_R.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: EDA Explore & Test: Test
    </h3>
</div>



<img src="../reference/R rattle/020 EDA Explore n Test/a024.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:42:02 x86_64-pc-linux-gnu 

# Perform Test 

# Use the fBasics package for statistical tests.

library(fBasics, quietly=TRUE)

# Perform the test.

locationTest(na.omit(crs$dataset[, "Male.Prevalence"]), na.omit(crs$dataset[, "Female.Prevalence"]))
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a025.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:46:39 x86_64-pc-linux-gnu 

# Perform Test 

# Use the fBasics package for statistical tests.

library(fBasics, quietly=TRUE)

# Perform the test.

locationTest(na.omit(crs$dataset[, "Prevalence"]), na.omit(crs$dataset[, "Hispanic.Prevalence"]))
```

---


<img src="../reference/R rattle/020 EDA Explore n Test/a026.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 11:47:53 x86_64-pc-linux-gnu 

# Perform Test 

# Use the fBasics package for statistical tests.

library(fBasics, quietly=TRUE)

# Perform the test.

locationTest(na.omit(crs$dataset[crs$dataset[["Prevalence_Risk4"]] == "High", "Prevalence"]), na.omit(crs$dataset[crs$dataset[["Prevalence_Risk4"]] == "Low", "Prevalence"]))
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">R Rattle Tool: Process & Transform Data</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: Process & Transform Data: Select Variables
    </h3>
</div>


```{r}
names(crs$dataset)
```

**Select variables to build classification model**

Target: 

* Prevalence_Risk4

Inputs:

* Denominator

* Year

* Source

* State_Full2




<img src="../reference/R rattle/030 Process n Transform Data/a001.png" align="left">

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:03:30 x86_64-pc-linux-gnu 

# Action the user selections from the Data tab. 

# Build the train/validate/test datasets.

# nobs=1692 train=1184 validate=254 test=254

set.seed(88)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.7*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  sample(0.15*crs$nobs) ->
crs$validate

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) %>%
  setdiff(crs$validate) ->
crs$test

# The following variable selections have been noted.

crs$input     <- c("Denominator", "Year", "Source", "State_Full2")

crs$numeric   <- c("Denominator", "Year")

crs$categoric <- c("Source", "State_Full2")

crs$target    <- "Prevalence_Risk4"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("State", "Prevalence", "Lower.CI", "Upper.CI", "Source_Full1", "State_Full1", "Numerator_ASD", "Numerator_NonASD", "Proportion", "Chi_Wilson_Corrected_Lower.CI", "Chi_Wilson_Corrected_Upper.CI", "Male.Prevalence", "Male.Lower.CI", "Male.Upper.CI", "Female.Prevalence", "Female.Lower.CI", "Female.Upper.CI", "Non.hispanic.white.Prevalence", "Non.hispanic.white.Lower.CI", "Non.hispanic.white.Upper.CI", "Non.hispanic.black.Prevalence", "Non.hispanic.black.Lower.CI", "Non.hispanic.black.Upper.CI", "Hispanic.Prevalence", "Hispanic.Lower.CI", "Hispanic.Upper.CI", "Asian.or.Pacific.Islander.Prevalence", "Asian.or.Pacific.Islander.Lower.CI", "Asian.or.Pacific.Islander.Upper.CI", "Source_UC", "Source_Full3", "Prevalence_Risk2", "Year_Factor")
crs$weights   <- NULL
```

---

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:17:02 x86_64-pc-linux-gnu 

# The 'gplots' package provides the 'barplot2' function.

library(gplots, quietly=TRUE)

#=======================================================================
# Rattle timestamp: 2019-12-23 12:17:02 x86_64-pc-linux-gnu 

# Bar Plot 

# Generate the summary data for plotting.

ds <- rbind(summary(na.omit(crs$dataset[crs$train,]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="High",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Low",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Medium",]$Source)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Very High",]$Source)))

# Sort the entries.

ord <- order(ds[1,], decreasing=TRUE)

# Plot the data.

bp <-  barplot2(ds[,ord], beside=TRUE, ylab="Frequency", xlab="Source", ylim=c(0, 715), col=colorspace::rainbow_hcl(5))

# Add the actual frequencies.

text(bp, ds[,ord]+24, ds[,ord])

# Add a legend to the plot.

legend("topright", bty="n", c("All","High","Low","Medium","Very High"),  fill=colorspace::rainbow_hcl(5))

# Add a title to the plot.

title(main="Distribution of Source (sample)\nby Prevalence_Risk4",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#=======================================================================
# Rattle timestamp: 2019-12-23 12:17:02 x86_64-pc-linux-gnu 

# Bar Plot 

# Generate the summary data for plotting.

ds <- rbind(summary(na.omit(crs$dataset[crs$train,]$State_Full2)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="High",]$State_Full2)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Low",]$State_Full2)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Medium",]$State_Full2)),
    summary(na.omit(crs$dataset[crs$train,][crs$dataset[crs$train,]$Prevalence_Risk4=="Very High",]$State_Full2)))

# Sort the entries.

ord <- order(ds[1,], decreasing=TRUE)

# Plot the data.

bp <-  barplot2(ds[,ord], beside=TRUE, ylab="Frequency", xlab="State_Full2", ylim=c(0, 37), col=colorspace::rainbow_hcl(5))

# Add a legend to the plot.

legend("topright", bty="n", c("All","High","Low","Medium","Very High"),  fill=colorspace::rainbow_hcl(5))

# Add a title to the plot.

title(main="Distribution of State_Full2 (sample)\nby Prevalence_Risk4",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
```

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:14:28 x86_64-pc-linux-gnu 

# Display histogram plots for the selected variables. 

# Use ggplot2 to generate histogram plot for Denominator

# Generate the plot.

p01 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Denominator, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Denominator)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Denominator\n\nRattle 2019-Dec-23 12:14:28 iss-user") +
  ggplot2::ggtitle("Distribution of Denominator (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Use ggplot2 to generate histogram plot for Year

# Generate the plot.

p02 <- crs %>%
  with(dataset[train,]) %>%
  dplyr::mutate(Prevalence_Risk4=as.factor(Prevalence_Risk4)) %>%
  dplyr::select(Year, Prevalence_Risk4) %>%
  ggplot2::ggplot(ggplot2::aes(x=Year)) +
  ggplot2::geom_density(lty=3) +
  ggplot2::geom_density(ggplot2::aes(fill=Prevalence_Risk4, colour=Prevalence_Risk4), alpha=0.55) +
  ggplot2::xlab("Year\n\nRattle 2019-Dec-23 12:14:28 iss-user") +
  ggplot2::ggtitle("Distribution of Year (sample)\nby Prevalence_Risk4") +
  ggplot2::labs(fill="Prevalence_Risk4", y="Density")

# Display the plots.

gridExtra::grid.arrange(p01, p02)
```

**Above shows that Denominator is skrewed, which need rescale transformation**


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: Process & Transform Data: Rescale (log transformation)
    </h3>
</div>



<img src="../reference/R rattle/030 Process n Transform Data/a004.png" align="left">

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:19:08 x86_64-pc-linux-gnu 

# Transform variables by rescaling. 

# Rescale Denominator.

crs$dataset[["R10_Denominator"]] <- crs$dataset[["Denominator"]]

# Take a log10 transform of the variable - treat -Inf as NA.

if (building)
{
  crs$dataset[["R10_Denominator"]] <-  log10(crs$dataset[["Denominator"]]) 
  crs$dataset[crs$dataset[["R10_Denominator"]] == -Inf & ! is.na(crs$dataset[["R10_Denominator"]]), "R10_Denominator"] <- NA
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R10_Denominator"]] <-  log10(crs$dataset[["Denominator"]]) 
  crs$dataset[crs$dataset[["R10_Denominator"]] == -Inf & ! is.na(crs$dataset[["R10_Denominator"]]), "R10_Denominator"] <- NA
}

#=======================================================================
# Rattle timestamp: 2019-12-23 12:19:08 x86_64-pc-linux-gnu 

# Action the user selections from the Data tab. 

# The following variable selections have been noted.

crs$input     <- c("Year", "Source", "State_Full2",
                   "R10_Denominator")

crs$numeric   <- c("Year", "R10_Denominator")

crs$categoric <- c("Source", "State_Full2")

crs$target    <- "Prevalence_Risk4"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("State", "Denominator", "Prevalence", "Lower.CI", "Upper.CI", "Source_Full1", "State_Full1", "Numerator_ASD", "Numerator_NonASD", "Proportion", "Chi_Wilson_Corrected_Lower.CI", "Chi_Wilson_Corrected_Upper.CI", "Male.Prevalence", "Male.Lower.CI", "Male.Upper.CI", "Female.Prevalence", "Female.Lower.CI", "Female.Upper.CI", "Non.hispanic.white.Prevalence", "Non.hispanic.white.Lower.CI", "Non.hispanic.white.Upper.CI", "Non.hispanic.black.Prevalence", "Non.hispanic.black.Lower.CI", "Non.hispanic.black.Upper.CI", "Hispanic.Prevalence", "Hispanic.Lower.CI", "Hispanic.Upper.CI", "Asian.or.Pacific.Islander.Prevalence", "Asian.or.Pacific.Islander.Lower.CI", "Asian.or.Pacific.Islander.Upper.CI", "Source_UC", "Source_Full3", "Prevalence_Risk2", "Year_Factor")
crs$weights   <- NULL
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    R Rattle Tool: Process & Transform Data: Rescale (normalization)
    </h3>
</div>



<img src="../reference/R rattle/030 Process n Transform Data/a005.png" align="left">


<img src="../reference/R rattle/030 Process n Transform Data/a006.png" align="left">

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:23:45 x86_64-pc-linux-gnu 

# Transform variables by rescaling. 

# The 'reshape' package provides the 'rescaler' function.

library(reshape, quietly=TRUE)

# Rescale Year.

crs$dataset[["RMD_Year"]] <- crs$dataset[["Year"]]

# Rescale by subtracting median and dividing by median abs deviation.

if (building)
{
  crs$dataset[["RMD_Year"]] <-  rescaler(crs$dataset[["Year"]], "robust")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RMD_Year"]] <- (crs$dataset[["Year"]] - 2007.000000)/5.930400
}

# Rescale R10_Denominator.

crs$dataset[["RMD_R10_Denominator"]] <- crs$dataset[["R10_Denominator"]]

# Rescale by subtracting median and dividing by median abs deviation.

if (building)
{
  crs$dataset[["RMD_R10_Denominator"]] <-  rescaler(crs$dataset[["R10_Denominator"]], "robust")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RMD_R10_Denominator"]] <- (crs$dataset[["R10_Denominator"]] - 5.548179)/0.598315
}

#=======================================================================
# Rattle timestamp: 2019-12-23 12:23:45 x86_64-pc-linux-gnu 

# Action the user selections from the Data tab. 

# The following variable selections have been noted.

crs$input     <- c("Source", "State_Full2", "RMD_Year",
                   "RMD_R10_Denominator")

crs$numeric   <- c("RMD_Year", "RMD_R10_Denominator")

crs$categoric <- c("Source", "State_Full2")

crs$target    <- "Prevalence_Risk4"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("State", "Denominator", "Prevalence", "Lower.CI", "Upper.CI", "Year", "Source_Full1", "State_Full1", "Numerator_ASD", "Numerator_NonASD", "Proportion", "Chi_Wilson_Corrected_Lower.CI", "Chi_Wilson_Corrected_Upper.CI", "Male.Prevalence", "Male.Lower.CI", "Male.Upper.CI", "Female.Prevalence", "Female.Lower.CI", "Female.Upper.CI", "Non.hispanic.white.Prevalence", "Non.hispanic.white.Lower.CI", "Non.hispanic.white.Upper.CI", "Non.hispanic.black.Prevalence", "Non.hispanic.black.Lower.CI", "Non.hispanic.black.Upper.CI", "Hispanic.Prevalence", "Hispanic.Lower.CI", "Hispanic.Upper.CI", "Asian.or.Pacific.Islander.Prevalence", "Asian.or.Pacific.Islander.Lower.CI", "Asian.or.Pacific.Islander.Upper.CI", "Source_UC", "Source_Full3", "Prevalence_Risk2", "Year_Factor", "R10_Denominator")
crs$weights   <- NULL
```

**Optionally, Cleanup variables by Delete Ignored**


<img src="../reference/R rattle/030 Process n Transform Data/a007.png" align="left">


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">R Rattle Tool: Train Model</span>


```{r}
crs$target
```

```{r}
crs$input
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Non-Linear Model: Decision Tree (DT)
    </h3>
</div>



<img src="../reference/R rattle/040 Train Model/DT001.png" align="left"> 


<img src="../reference/R rattle/040 Train Model/DT002.png" align="left"> 

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:38:55 x86_64-pc-linux-gnu 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(Prevalence_Risk4 ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0),
    model=TRUE)

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.04 secs

#=======================================================================
# Rattle timestamp: 2019-12-23 12:38:59 x86_64-pc-linux-gnu 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree ADV_ASD_State_R.csv $ Prevalence_Risk4")

# List the rules from the tree using a Rattle support function.

asRules(crs$rpart)
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}


#=======================================================================
# Rattle timestamp: 2019-12-23 12:34:57 x86_64-pc-linux-gnu 

# Build a Random Forest model using the traditional approach.

set.seed(crv$seed)

crs$rf <- randomForest::randomForest(Prevalence_Risk4 ~ .,
  data=crs$dataset[crs$train, c(crs$input, crs$target)], 
  ntree=300,
  mtry=2,
  importance=TRUE,
  na.action=randomForest::na.roughfix,
  replace=FALSE)

# Generate textual output of the 'Random Forest' model.

crs$rf

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 0.44 secs
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}
head(ASD_State)
```

```{r}
# Filter [ Source: ADDM ], including only two clomuns for SLR:
# Dependent variable: Prevalence
# independent variable: Year
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'ADDM', select = c(Prevalence, Year))
#
dim(ASD_State_4_SLR)
head(ASD_State_4_SLR)
```

---


**SLR Workshop Task: <span style="color:blue">1. a. Graph the data in a scatterplot to determine if there is a possible linear relationship.</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

---


**SLR Workshop Task: <span style="color:blue">2. b. Compute and interpret the linear correlation coefficient, r.</span>**


Compute correlaion coefficient

```{r}
cor(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

Apply correlation test (two tail: != 0)

```{r}
cor.test(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

Apply correlation test (one tail: > 0)

```{r}
cor.test(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence, alternative = "greater")
```

---


**SLR Workshop Task: <span style="color:blue">3. c. Determine the regression equation for the data.</span>**

```{r}
fit_model = lm(formula = Prevalence ~ Year, data = ASD_State_4_SLR)
print(fit_model)
```

---


**SLR Workshop Task: <span style="color:blue">4. d. Graph the regression equation and the data points.</span>**

```{r}
plot(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
abline(fit_model, col="blue", lwd=2)
```

---


**SLR Workshop Task: <span style="color:blue">5. e. Identify potential influential observations (outliers).</span>**

```{r}
# library(repr)
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=6)
par(mfrow=c(2, 2)) 
plot(fit_model)
par(mfrow=c(1, 1))
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* Based on **Residual vs Leverage** chart, there seems no potential influential observations (outliers)



---


**SLR Workshop Task: <span style="color:blue">6. f. At the 5% significance level, do the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that [ Year ] is useful as a predictor of ASD [ Prevalence ]?</span>**

```{r}
summary(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice:**

2. F-test's p-value is 4.13e-15, which is smaller than 0.05, thus above 95% confidence.


---


**SLR Workshop Task: <span style="color:blue">7. g.	Obtain the residuals and create a residual plot. Decide whether it is reasonable to consider that the assumptions for regression analysis are met by the variables in questions.</span>**

```{r}
# library(repr)
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=6)
par(mfrow=c(2, 2)) 
plot(fit_model)
par(mfrow=c(1, 1))
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* Based on **Residual vs Fitted, Sacle-Location, and Normal Q-Q** charts, the residuals (vs fitted) are following linear assumption, with slightly "fan-shape" at larger Year values (Heteroscedasticity). https://statisticsbyjim.com/regression/heteroscedasticity-regression/

* We are to explore polynomial regression method for this issue later.


---


**SLR Workshop Task: <span style="color:blue">8. h.	Compute and interpret the coefficient of determination, $R^2$.</span>**

```{r}
summary(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* $R^2$ is  0.5219

* Adjusted $R^2$ is  0.5162


---


**SLR Workshop Task: <span style="color:blue">9. i.	Find the predicted ASD Prevalence of future Year.</span>**

```{r}
future_year = 2025
newdata = data.frame(Year = future_year) 
predict(fit_model,newdata)
#
cat("Predicted ASD Prevalence of Year [", future_year, "] is", round(predict(fit_model,newdata), 1), "per 1,000 Children")

```

---


**SLR Workshop Task: <span style="color:blue">10. j.	Determine a 95% confidence interval for the predicted ASD Prevalence.</span>**

```{r}
predict(fit_model, newdata, interval = "predict")
```

```{r}
cat("\nPredicted ASD Prevalence of Year [", future_year, "] (95% Upper CI) is", 
    round(predict(fit_model,newdata, interval = "predict")[3], 1), "per 1,000 Children")

cat("\nPredicted ASD Prevalence of Year [", future_year, "] (95% Lower CI) is", 
    round(predict(fit_model,newdata, interval = "predict")[2], 1), "per 1,000 Children")

```

---


<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        Quiz:
    </h3>
    <p>
        Create Prevalence ~ Year SLR model for Data Source: SPED
    </p>
</div>

```{r}
# Write your code below and press Shift+Enter to execute 

```

Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'SPED', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'NSCH', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'MEDI', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, select = c(Prevalence, Year))

-->


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Multiple Linear Regression (MLR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Multiple Linear Regression (MLR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value)

3. c.	Visualize Data and trends

4. d.	Compute correlation between variables and apply multiple regression.

5. e.	Check multicollinearity, then how to remove multicollinearity.

6. f.	How is your ﬁnal model looks like?



**MLR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
# ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
# ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
# ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
# ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
names(ASD_State)
```

```{r}
# Filter to include relevant clomuns for MLR:
# Dependent variable: Prevalence
# independent variable: Let's include all at the moment
ASD_State_4_MLR = ASD_State
#
dim(ASD_State_4_MLR)
head(ASD_State_4_MLR)
```

---


**MLR Workshop Task: <span style="color:blue">2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value).</span>**

```{r}
summary(ASD_State_4_MLR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_MLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_MLR, 2, function(col_x)sum(is.na(col_x))))
```

```{r}
dim(ASD_State_4_MLR)
```

```{r}
#Get all the column variables which contains missing value 
NA_Column_Names <- names(ASD_State_4_MLR[0, colSums(is.na(ASD_State_4_MLR)) > 0])
#
NA_Column_Names
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% NA_Column_Names)]
#
head(ASD_State_4_MLR)
```

**No missing values, as they have been handled earlier. <span style="color:blue">Hurrah!</span>**

**But some varialbe contains <span style="color:blue">"leaky"</span> information, which can be used to directly calculate the dependent variable: Prevalence. This won't happen in real world scenario, thus they need to be removed.**

```{r}
cbind(names(ASD_State_4_MLR), c(1:length(names(ASD_State_4_MLR))))
```

```{r}
Leaky_Column_Names = c('Lower.CI', 'Upper.CI', 'Numerator_ASD', 'Numerator_NonASD', 'Proportion', 
                       'Chi_Wilson_Corrected_Lower.CI', 'Chi_Wilson_Corrected_Upper.CI', 
                       'Prevalence_Risk2', 'Prevalence_Risk4')
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% Leaky_Column_Names)]
#
head(ASD_State_4_MLR)
```

**Remove redundant/duplicate variables (aliased coefficients), retaining one for each type of information is enough:**

https://en.wikipedia.org/wiki/Multicollinearity

https://stats.stackexchange.com/questions/112442/what-are-aliased-coefficients

```{r}
Redundant_Column_Names = c('State', 'Source_Full1', 'State_Full1', 'Source_UC', 'Source_Full3', 'Year_Factor')
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% Redundant_Column_Names)]
#
head(ASD_State_4_MLR)
```

---


**MLR Workshop Task: <span style="color:blue">3. c.	Visualize the data to gain insights</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_MLR$Year, ASD_State_4_MLR$Prevalence)
```

```{r}
plot(as.factor(ASD_State_4_MLR$Year), ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$Denominator, ASD_State_4_MLR$Prevalence)
```

```{r}
# To use bin() function
# https://www.rdocumentation.org/packages/OneR/versions/2.2/topics/bin
if(!require(OneR)){install.packages("OneR")}
library('OneR')

# Bin 'Denominator'
plot(bin(ASD_State_4_MLR$Denominator, nbins = 10), ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$Source, ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$State_Full2, ASD_State_4_MLR$Prevalence)
```

---


**MLR Workshop Task: <span style="color:blue">4. d.	Compute correlation between variables and apply multiple regression.</span>**


Recode categorical variable to dummy (numeric) variable using one-hot encoding:

```{r}
# To use select_if() function
if(!require(dplyr)){install.packages("dplyr")}
library("dplyr")

summary(select_if(ASD_State_4_MLR, is.numeric))
```

```{r}
correlation = cor(select_if(ASD_State_4_MLR, is.numeric))
correlation
```

```{r}
# Variable's correlation against target dependent variable:
correlation[, 2]
```

```{r}
if(!require(corrplot)){install.packages("corrplot")}
library("corrplot")
corrplot(correlation, tl.col="black", tl.pos = "lt")
```

```{r}
str(ASD_State_4_MLR)
```

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model = lm(Prevalence ~ . - State_Full2, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.6575
    </p>
</div>


```{r}
# To build (US. State level) ASD Prevalence predictive model for specific state's prevalence:
# In situations that we shall know the US. State name. (A state name is required during prediciton.)
fit_model = lm(Prevalence ~ . , data = ASD_State_4_MLR) # "~." means all other variables, including factors
#
summary(fit_model)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7697
    </p>
</div>



---


**MLR Workshop Task: <span style="color:blue">5. e.	Check multicollinearity, then how to remove multicollinearity.</span>**


< Detection of multicollinearity >

Some authors have suggested a formal detection-tolerance or the variance inflation factor (VIF) for multicollinearity. <span style="color:blue">A VIF of 5 or 10 and above</span> indicates a multicollinearity problem.

```{r}
# To use select_if() function
if(!require(car)){install.packages("car")}
library("car")
```

```{r}
vif(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice VIF of Denominator and State_Full2 are high.** Let's exclude them one at a time.


**Retain: State; Remove: Denominator then re-build model:**

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model_with_State = lm(Prevalence ~ . - Denominator, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model_with_State)
```

```{r}
vif(fit_model_with_State)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7662
    </p>
</div>



---


**Retain: Denominator; Remove: State; then re-build model:**

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model_with_Denominator = lm(Prevalence ~ . - State_Full2, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model_with_Denominator)
```

```{r}
vif(fit_model_with_Denominator)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.6575
    </p>
</div>



---


**MLR Workshop Task: <span style="color:blue">6. f.	How is your ﬁnal model looks like?</span>**

<!-- #region -->
* During prediction, if US. State name will be known, then the **fit_model_with_State** can be better because it has higher $R^2$ value.


* During prediction, if US. State name will NOT be known,  then the **fit_model_with_Denominator** can be adopted because it doesn't require state name as input for prediciton.

<!-- #endregion -->

**MLR Prediciton 1**

Let's use **fit_model_with_State** to predict CA-California ASD Prevalence of Year 2016 if ADDM would have conducted a survey

```{r}
newdata = ASD_State_4_MLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 50000
newdata$Year = 2016
newdata$Source = "addm"
#newdata$State_Full2 = "CA-California"
newdata$State_Full2 = "AZ-Arizona"

newdata
```

```{r}
predict(fit_model_with_State, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model_with_State, newdata), 1), "per 1,000 Children")
```

**MLR Prediciton 2**

Let's use **fit_model_with_Denominator** to predict National level ASD Prevalence of Year 2016 if ADDM would have conducted a survey

```{r}
predict(fit_model_with_Denominator, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model_with_Denominator, newdata), 1), "per 1,000 Children")
```

**MLR Prediciton 2**

Let's use **fit_model** to predict FL-Florida State level ASD Prevalence of Year 2025 if SPED will conduct a record review/survey of 2,600,000 children.

```{r}
newdata = ASD_State_4_MLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 2600000
newdata$Year = 2025
newdata$Source = "sped"
newdata$State_Full2 = "FL-Florida"

newdata
```

```{r}
predict(fit_model, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model, newdata), 1), "per 1,000 Children")
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Polynomial (Linear) Regression (PLR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Polynomial (Linear) Regression (PLR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value)

3. c.	Visualize Data and trends

4. d.	Compute correlation between variables and apply multiple regression.

5. e.	Multiple polynomial regression.



**PLR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
names(ASD_State)
```

```{r}
# Filter [ Source: SPED ], including only two clomuns for SLR:
# Dependent variable: Prevalence
# independent variable: Year
# ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'MN-Minnesota', select = c(Prevalence, Year))
# ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'MS-Mississippi', select = c(Prevalence, Year))
ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'FL-Florida', select = c(Prevalence, Year))
#
dim(ASD_State_4_PLR)
head(ASD_State_4_PLR)
```

---


**PLR Workshop Task: <span style="color:blue">2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value).</span>**

```{r}
summary(ASD_State_4_PLR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_PLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_PLR, 2, function(col_x)sum(is.na(col_x))))
```

**No missing values**


---


**PLR Workshop Task: <span style="color:blue">3. c.	Visualize the data to gain insights</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_PLR$Year, ASD_State_4_PLR$Prevalence)
```

---


**PLR Workshop Task: <span style="color:blue">4. d.	Compute correlation between variables and apply multiple regression.</span>**


Recode categorical variable to dummy (numeric) variable using one-hot encoding:

```{r}
# To use select_if() function
if(!require(dplyr)){install.packages("dplyr")}
library("dplyr")

summary(select_if(ASD_State_4_PLR, is.numeric))
```

```{r}
correlation = cor(select_if(ASD_State_4_PLR, is.numeric))
correlation
```

```{r}
# Variable's correlation against target dependent variable:
correlation[, 1]
```

```{r}
str(ASD_State_4_PLR)
```

```{r}
# SLR
fit_model_SLR = lm(Prevalence ~ Year , data = ASD_State_4_PLR)
#
summary(fit_model_SLR)
```

```{r}
plot(fit_model_SLR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.958
    </p>
</div>


```{r}
# PLR (quadratic)
fit_model_PLR = lm(Prevalence ~ Year + I(Year^2), data = ASD_State_4_PLR)
#
summary(fit_model_PLR)
```

**Abount I() function:** https://stackoverflow.com/questions/8055508/in-r-formulas-why-do-i-have-to-use-the-i-function-on-power-terms-like-y-i


```{r}
plot(fit_model_PLR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.9981
    </p>
</div>



**Visualise the difference between SLR & PLR:**

```{r}
plot(ASD_State_4_PLR$Year, ASD_State_4_PLR$Prevalence)
# add SLR line
lines(ASD_State_4_PLR$Year, predict(fit_model_SLR, ASD_State_4_PLR), col="red", lwd=2) # or # abline(fit_model_SLR, col="red", lwd=2)
# add PLR line
lines(ASD_State_4_PLR$Year, predict(fit_model_PLR, ASD_State_4_PLR), col="orange", lwd=2) 
```

---


**PLR Prediciton**


```{r}
newdata = ASD_State_4_PLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Year = 2025

newdata
```

```{r}
predict(fit_model_PLR, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence of Year [", newdata$Year, "] is", round(predict(fit_model_PLR, newdata), 1), "per 1,000 Children")

```

---


**Multiple PLR Workshop Task: <span style="color:blue">5. e.	Multiple polynomial regression (MPR).</span>** (Enhance MLR by adding higher order transformed variables.)


**Resuse MLR data: <span style="color:blue">ASD_State_4_MLR</span>** Cop to new dataframe: ASD_State_4_MPR

```{r}
ASD_State_4_MPR = ASD_State_4_MLR

dim(ASD_State_4_MPR)

```

```{r}
summary(ASD_State_4_MPR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_MLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_MLR, 2, function(col_x)sum(is.na(col_x))))
```

**Build Multiple PLR model: + I(Year^2) + I(log(Denominator)**

```{r}
fit_model_MPR = lm(Prevalence ~ . + I(Year^2) + I(log(Denominator)), data = ASD_State_4_MPR) # "~." means all other variables, including factors
#
summary(fit_model_MPR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7884
    </p>
</div>



**Mutiple PLR Prediciton**

```{r}
# Copy datastructure
newdata = subset(ASD_State_4_MPR, ASD_State_4_MPR$Year == 2016 &
                            ASD_State_4_MPR$State_Full2 == 'FL-Florida' & 
                            ASD_State_4_MPR$Source == 'sped')
newdata
```

```{r}
newdata = ASD_State_4_MPR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 2600000
newdata$Year = 2025
newdata$Source = "sped"
newdata$State_Full2 = "FL-Florida"

newdata
```

```{r}
predict(fit_model_MPR, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence of Year [", newdata$Year, "] is", round(predict(fit_model_MPR,newdata), 1), "per 1,000 Children")

```

<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        Quiz:
    </h3>
    <p>
        Compare predicted ASD prevalence and model $R^2$ between: Multiple Linear Rregression and Multiple Polynomial Rregression.
    </p>
    <p>
        Which prediction result would you use? Provide yor justifications.
    </p>
</div>

```{r}
# Write your code below and press Shift+Enter to execute 

```

Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
# TBD

-->


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Logistic Regression (LR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Logistic Regression (LR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Logistic regression - Binary Class.

3. c.	Logistic regression - Multi-Class.



**LR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
# ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
# ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
# ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
# ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
Column_Names = c("Prevalence_Risk2", "Denominator", "Year", "Source", "State_Full2")
ASD_State_4_LR_Risk2 <- ASD_State[ , (names(ASD_State) %in% Column_Names)]
dim(ASD_State_4_LR_Risk2)
head(ASD_State_4_LR_Risk2)
```

```{r}
Column_Names = c("Prevalence_Risk4", "Denominator", "Year", "Source", "State_Full2")
ASD_State_4_LR_Risk4 <- ASD_State[ , (names(ASD_State) %in% Column_Names)]
dim(ASD_State_4_LR_Risk4)
head(ASD_State_4_LR_Risk4)
```

---


**LR Workshop Task: <span style="color:blue">2. b.	Logistic regression (LR) Binary Class.</span>** (Reuse Multiple Polynomial Model on categorical dependent variable.)

```{r}
table(ASD_State_4_LR_Risk2$Prevalence_Risk2)
barplot(table(ASD_State_4_LR_Risk2$Prevalence_Risk2))
```

```{r}
counts = table(ASD_State_4_LR_Risk2$Prevalence_Risk2, ASD_State_4_LR_Risk2$Source)
counts
barplot(counts,
        main="Prevalence by Data Sources and Risk Levels",
        xlab="Data Sources",
        ylab="Occurrences",
        col=c("white", "lightgrey"),
        legend = rownames(counts), 
        args.legend = list(x = "topleft", bty = "n", cex = 0.85, y.intersp = 4))

```

```{r}
str(ASD_State_4_LR_Risk2)
```

**Build model**

```{r}
# Binary Classification:
fit_model_LR_Risk2 = glm(Prevalence_Risk2 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                         family=binomial(link='logit'), data = ASD_State_4_LR_Risk2)
#
summary(fit_model_LR_Risk2)

```

**Evaluate model**

```{r}
# Likelihood ratio test: significance of the difference between the full model and the null model.
pchisq(fit_model_LR_Risk2$null.deviance - fit_model_LR_Risk2$deviance, 
       fit_model_LR_Risk2$df.null - fit_model_LR_Risk2$df.residual, lower.tail = FALSE)

```

**Check whether above value is very small (the smaller the more significant), e.g. < 0.05.**


< How to perform a Logistic Regression in R > Michy Alice

https://www.r-bloggers.com/how-to-perform-a-logistic-regression-in-r/


```{r}
# null deviance and the residual deviance
anova(fit_model_LR_Risk2, test="Chisq")
```

```{r}
# R^2 equivalent
if(!require(pscl)){install.packages("pscl")}
library("pscl")
```

While no exact equivalent to the $R^2$ of linear regression exists, the **McFadden $R^2$** index can be used to assess the model fit.

```{r}
# R^2 equivalent
pR2(fit_model_LR_Risk2)[4]
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        McFadden $R^2$ = 0.6374
    </p>
</div>



---


**LR Workshop Task: <span style="color:blue">3. c.	Logistic regression (LR) Muti-Class.</span>** (Reuse Multiple Polynomial Model on categorical dependent variable.)

```{r}
table(ASD_State_4_LR_Risk4$Prevalence_Risk4)
barplot(table(ASD_State_4_LR_Risk4$Prevalence_Risk4))
```

```{r}
counts = table(ASD_State_4_LR_Risk4$Prevalence_Risk4, ASD_State_4_LR_Risk4$Source)
counts
barplot(counts,
        main="Prevalence Occurrence by Source and Risk",
        xlab="Data Sources",
        ylab="Occurrences",
        col=c("lightyellow", "orange", "red","darkred"),
        legend = rownames(counts), 
        args.legend = list(x = "topleft", bty = "n", cex = 0.85, y.intersp = 4))

```

**Build model**

```{r}
# multinom function from the nnet package 
if(!require(nnet)){install.packages("nnet")}
library("nnet")
```

```{r}
# Multi-Class Classification:
fit_model_LR_Risk4 = multinom(Prevalence_Risk4 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                     data = ASD_State_4_LR_Risk4, maxit=1000) # maxit https://cran.r-project.org/web/packages/nnet/nnet.pdf

summary(fit_model_LR_Risk4)

```

< MULTINOMIAL LOGISTIC REGRESSION | R DATA ANALYSIS EXAMPLES >

https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/

```{r}
## extract the coefficients from the model and exponentiate
exp(coef(fit_model_LR_Risk4))
# Uncomment below to display all p values:
# paste(exp(coef(fit_model)))
```

```{r}
# Test the significance/importance of each coefficient (check if p values < 0.05)

# z score for coefficients
z <- summary(fit_model_LR_Risk4)$coefficients/summary(fit_model_LR_Risk4)$standard.errors
cat('\n< Talbe of coefficient z scores>')
z

# p value of 2-tailed z test
p <- (1 - pnorm(abs(z), 0, 1)) * 2
cat('\n< Talbe of coefficient p values>')
p
# Uncomment below to display all p values:
# paste(p)
```

While no exact equivalent to the $R^2$ of linear regression exists, the **McFadden $R^2$** index can be used to assess the model fit.

```{r}
# R^2 equivalent
pR2(fit_model_LR_Risk4)[4]
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        McFadden $R^2$ = 0.6122
    </p>
</div>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Model Evaluation</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Linear Model: Model Evaluation - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Train/Test Dataset Split
2. b.	Confusion Matrix & Accuracy for Classification
3. c.	K-Fold Cross Validation
4. d.	$R^2$, MSE, RMSE for Regression for Regression


**Model Evaluation Workshop Task: <span style="color:blue">1. a.	Train/Test Dataset Split</span>**

```{r}
if(!require(caTools)){install.packages("caTools")}
library("caTools") 
```

```{r}
# Generate a random number sequence that can be reproduced to check results thru the seed number.
set.seed(88)

# Stratified Random Sampling: split dataset into two sets in predefined proportion (SplitRatio)
# while preserving differnt class ratios of dependent variable. (e.g. Proportion of Low/High)
split <- sample.split(ASD_State_4_LR_Risk2$Prevalence_Risk2, SplitRatio = 0.7)
```

```{r}
# Get training and test data
trainset <- subset(ASD_State_4_LR_Risk2, split == TRUE) 
testset <- subset(ASD_State_4_LR_Risk2, split == FALSE)
```

**Build a binary classification model to predict (categorical) Prevalence Risk Level using Logistic Regression (LR)**

```{r}
# Binary Classification:
fit_model_LR_Risk2 = glm(Prevalence_Risk2 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                         family=binomial(link='logit'), data = trainset) # data = trainset

summary(fit_model_LR_Risk2)

```

**Model Evaluation Workshop Task: <span style="color:blue">2. b.	Confusion Matrix & Accuracy for Classification</span>**


https://en.wikipedia.org/wiki/Confusion_matrix

```{r}
# Confusion matrix on Trainset
probTrainset <- predict(fit_model_LR_Risk2, type = 'response')
# One way is to use the proportion of High risk in the *Training* data.
threshold2 <- sum(trainset$Prevalence_Risk2 == "High")/length(trainset$Prevalence_Risk2)
cat('Trainset High Risk Threshold = ', threshold2)
# If logistic regression probability > threshold, predict High, else predict Low.
predictTrainset <- ifelse(probTrainset > threshold2, "High", "Low")
# Create a contingency table (Confusion Matrix) with actuals on rows and predictions on columns.
table(trainset$Prevalence_Risk2, predictTrainset)

# Accuracy on Trainset
AccuracyTrain <- mean(predictTrainset == trainset$Prevalence_Risk2) 
cat('Trainset Accuracy = ', AccuracyTrain)
```

```{r}
# Confusion matrix on Testset
probTestset <- predict(fit_model_LR_Risk2, newdata = testset, type = 'response') # newdata = testset
# One way is to use the proportion of High risk in the *Training* data.
cat('Reused Trainset High Risk Threshold = ', threshold2)
# If logistic regression probability > threshold, predict High, else predict Low.
predictTestset <- ifelse(probTestset > threshold2, "High", "Low")
# Create a contingency table (Confusion Matrix) with actuals on rows and predictions on columns.
table(testset$Prevalence_Risk2, predictTestset)

# Accuracy on Trainset
AccuracyTest <- mean(predictTestset == testset$Prevalence_Risk2) 
cat('Testset Accuracy = ', AccuracyTest)
```

**Model Evaluation Workshop Task: <span style="color:blue">3. c.	K-Fold Cross Validation</span>**


### R caret package

The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for:

* data splitting
* pre-processing
* feature selection
* model tuning using resampling
* variable importance estimation

http://topepo.github.io/caret/index.html


```{r}
if(!require(caret)){install.packages("caret")}
library("caret")
```

```{r}
if(!require(e1071)){install.packages("e1071")}
library("e1071")
```

```{r}
# Caret train/test split method:
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_LR_Risk2$Prevalence_Risk2, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_LR_Risk2[caret_idx, ]
caret_testset  = ASD_State_4_LR_Risk2[-caret_idx, ]

#caret_threshold <- sum(caret_trainset$Prevalence_Risk2 == "Low")/length(caret_trainset$Prevalence_Risk2)
#caret_threshold
```

```{r}
# Caret logistic regresion
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)

caret_model_LR_Risk2 = train(form = Prevalence_Risk2 ~ ., data = caret_trainset, 
                             trControl = cv_control, method = "glm", family = "binomial")
#
caret_model_LR_Risk2
```

```{r}
# Get predicted class label
caret_model_LR_Risk2_Pred <- predict(caret_model_LR_Risk2, caret_testset)

# Uncomment below to get class probability
# caret_model_LR_Risk2_Pred <- predict(caret_model_LR_Risk2, caret_testset, type = "prob")

```

https://topepo.github.io/caret/using-your-own-model-in-train.html#Illustration5

```{r}
# CM & Acc
cm_table <- table(as.factor(caret_model_LR_Risk2_Pred), caret_testset$Prevalence_Risk2)
confusionMatrix(cm_table)
```

**Model Evaluation Workshop Task: <span style="color:blue">4. d.	$R^2$, MSE, RMSE for Regression</span>**

```{r}
# Caret train/test split method:
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_MLR$Prevalence, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_MLR[caret_idx, ]
caret_testset  = ASD_State_4_MLR[-caret_idx, ]
```

```{r}
# Look at below plots of train and test, shape of distribution are similar, which means good sampling.
par(mfrow=c(1, 2)) 
plot(density(caret_trainset$Prevalence))
plot(density(caret_testset$Prevalence))
par(mfrow=c(1, 1))
```

**Build a regression model to predict (numeric) Prevalanece using Multiple Linear Regression (MLR)**

```{r}
if(!require(elasticnet)){install.packages("elasticnet")}
library("elasticnet")
```

```{r}
# Caret MLR regresion
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)
#
caret_model_MLR <- train(Prevalence ~ ., data = caret_trainset, trControl = cv_control, method = "lm") 
#
caret_model_MLR
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=8)
ggplot(varImp(caret_model_MLR))
# plot(varImp(caret_model_MLR))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

---


**Enhanced MLR using Regularization: L1 Lasso**


https://towardsdatascience.com/create-predictive-models-in-r-with-caret-12baf9941236

```{r}
if(!require(elasticnet)){install.packages("elasticnet")}
library("elasticnet")
```

```{r}
# Caret MLR with Regularization
# possible method: boot", "boot632", "cv", "repeatedcv", "LOOCV", "LGOCV"
cv_control <- trainControl(method = "repeatedcv",   
                           number = 10,     # number of folds
                           repeats = 5)    # repeated N times

caret_model_MLR_L1 <- train(Prevalence ~ .,
               data = caret_trainset,
               method = "lasso",  # Try using "ridge"
               trControl = cv_control,
               preProcess = c('scale', 'center'))  # Auto pre-process data
#
caret_model_MLR_L1
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=2)
ggplot(varImp(caret_model_MLR_L1))
# plot(varImp(caret_model_MLR_L1))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR_L1, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

---


**Enhanced MLR using Regularization: L2 Ridge**

```{r}
# Caret MLR with Regularization
# possible method: boot", "boot632", "cv", "repeatedcv", "LOOCV", "LGOCV"
cv_control <- trainControl(method = "repeatedcv",   
                           number = 10,     # number of folds
                           repeats = 5)    # repeated N times

caret_model_MLR_L2 <- train(Prevalence ~ .,
               data = caret_trainset,
               method = "ridge",  # Try using "lasso"
               trControl = cv_control,
               preProcess = c('scale', 'center'))  # Auto pre-process data
#
caret_model_MLR_L2
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=2)
ggplot(varImp(caret_model_MLR_L2))
# plot(varImp(caret_model_MLR_L2))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR_L2, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Workshop Submission</span>



<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        What to submit?
    </h3>
    <p>
        Create predictive model for Multi Class Classification of ASD Prevalence Risk Level (Low, Medium, High, Very High) using Caret package's multinom logistic regression algorithm.
    </p>
</div>


References:

https://daviddalpiaz.github.io/r4sl/the-caret-package.html

http://topepo.github.io/caret/index.html

https://cran.r-project.org/web/packages/caret/caret.pdf


```{r}
# Code example of multinomial logistic regresion using Iris flower dataset
iris[c(1:3, 51:53, 101:103), ]
summary(iris)
iris_model = train(Species ~ ., data = iris, method = "multinom", 
                     trControl = trainControl(method = "cv", number = 5), trace = FALSE)
iris_model
```

```{r}
# Write your code below and press Shift+Enter to execute 

```

<!-- #region -->
Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
#
# < Multi Class Classification of ASD Prevalence Risk Level >
#
# ----------------------------------
# Caret train/test split method:
# ----------------------------------
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_LR_Risk4$Prevalence_Risk4, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_LR_Risk4[caret_idx, ]
caret_testset  = ASD_State_4_LR_Risk4[-caret_idx, ]

# ----------------------------------
# Caret multinomial logistic regresion
# ----------------------------------
# Cross Validation setting
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)
# Train model
caret_model_LR_Risk4 = train(form = Prevalence_Risk4 ~ ., data = caret_trainset, 
                             trControl = cv_control, method = "multinom", trace = FALSE)
#                             trControl = cv_control, method = "glm", family = "binomial")

# ----------------------------------
# Summary of model
# ----------------------------------
caret_model_LR_Risk4

# ----------------------------------
# Get predicted class label
# ----------------------------------
caret_model_LR_Risk4_Pred <- predict(caret_model_LR_Risk4, caret_testset)
head(caret_model_LR_Risk4_Pred)

# ----------------------------------
# Get predicted class probability
# ----------------------------------
caret_model_LR_Risk4_Pred_Prob <- predict(caret_model_LR_Risk4, caret_testset, type = "prob")
head(caret_model_LR_Risk4_Pred_Prob)

# ----------------------------------
# CM & Acc
# ----------------------------------
cm_table <- table(as.factor(caret_model_LR_Risk4_Pred), caret_testset$Prevalence_Risk4)
confusionMatrix(cm_table)


-->
<!-- #endregion -->

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




### Excellent! You have completed the workshop notebook!


**Connect with the author:**

This notebook was written by [GU Zhan (Sam)](https://sg.linkedin.com/in/zhan-gu-27a82823 "GU Zhan (Sam)").

[Sam](https://www.iss.nus.edu.sg/about-us/staff/detail/201/GU%20Zhan "GU Zhan (Sam)") is currently a lecturer in [Institute of Systems Science](https://www.iss.nus.edu.sg/ "NUS-ISS") in [National University of Singapore](http://www.nus.edu.sg/ "NUS"). He devotes himself into pedagogy & andragogy, and is very passionate in inspiring next generation of artificial intelligence lovers and leaders.



Copyright &copy; 2020 GU Zhan

This notebook and its source code are released under the terms of the [MIT License](https://en.wikipedia.org/wiki/MIT_License "Copyright (c) 2020 GU ZHAN").

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Appendices</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Interactive workshops: < Learning R inside R > using swirl() (in R/RStudio)
    </h3>
</div>



https://github.com/telescopeuser/S-SB-Workshop


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="https://github.com/dd-consulting">
         <img src="../reference/GZ_logo.png" width="60" align="right">
        https://github.com/dd-consulting
    </a>
</div>



---

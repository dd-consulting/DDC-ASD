---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.3.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="https://github.com/dd-consulting">
         <img src="../reference/GZ_logo.png" width="60" align="right">
    </a>
    <h1>
        One-Stop Analytics: Predictive Modeling (Regression Models)
    </h1>
</div>



# Case Study of Autism Spectrum Disorder (ASD) with R

---

<img src="../reference/CDC_ASD/CDC_ASD_01.jpg" align="left">

<img src="../reference/CDC_ASD/CDC_ASD_02.png" width="700" align="center">



## <span style="color:blue">[ United States ]</span> 

## Centers for Disease Control and Prevention (CDC) - Autism Spectrum Disorder (ASD)

Autism spectrum disorder (ASD) is a developmental disability that can cause significant social, communication and behavioral challenges. CDC is committed to continuing to provide essential data on ASD, search for factors that put children at risk for ASD and possible causes, and develop resources that help identify children with ASD as early as possible.

https://www.cdc.gov/ncbddd/autism/data/index.html



## <span style="color:blue">[ Singapore ]</span> 

## TODAY Online - More preschoolers diagnosed with developmental issues

Doctors cited better awareness among parents and preschool teachers, leading to early referrals for diagnosis.

https://www.gov.sg/news/content/today-online-more-preschoolers-diagnosed-with-developmental-issues

<img src="../reference/SG_ASD/SG_ASD_01.png" width="650" align="left">




<img src="../reference/SG_ASD/SG_ASD_04.png" align="left"> 

https://www.pathlight.org.sg/


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="60" align="right">
    </a>
</div>



# Workshop Objective: 

## Use R to predict Autism Spectrum Disorder (ASD) prevalence. 

https://www.cdc.gov/ncbddd/autism/data/index.html

* ## Linear Model: Simple Linear Regression (SLR)

* ## Linear Model: Multiple Linear Regression (MLR)

* ## Linear Model: Polynomial Regression (PLR)

* ## Linear Model: Logistic Regression (LR)

* ## Linear Model: Model Evaluation: Train/Test, K-Fold Cross Validation, Confusion Matrix

* ## Linear Model: Prevent Overfitting by Regularization Methods

* ## Workshop Submission

* ## Appendices


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>



```{r}
library("repr") # Show graphs in-line notebook
```

**Obtain current R <span style="color:blue">working directory</span>**

```{r}
getwd()
```

**Set new R working directory**

```{r}
# setwd("/media/sf_vm_shared_folder/git/DDC/DDC-ASD/model_R")
# setwd('~/Desktop/admin-desktop/vm_shared_folder/git/DDC-ASD/model_R')
getwd()
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Simple Linear Regression (SLR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Simple Linear Regression (SLR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Graph the data in a scatterplot to determine if there is a possible linear relationship.

2. b.	Compute and interpret the linear correlation coefficient, r.

3. c.	Determine the regression equation for the data.

4. d.	Graph the regression equation and the data points.

5. e.	Identify potential influential observations (outliers).

6. f.	At the 5% significance level, do the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that [ Year ] is useful as a predictor of ASD [ Prevalence ]?

7. g.	Obtain the residuals and create a residual plot. Decide whether it is reasonable to consider that the assumptions for regression analysis are met by the variables in questions.

8. h.	Compute and interpret the coefficient of determination, $R^2$.

9. i.	Find the predicted ASD Prevalence of future Year.

10. j.	Determine a 95% confidence interval for the predicted ASD Prevalence.



**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
# Convert Year_Factor to ordered.factor
ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) 
ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, 
                                    levels=c("Low", "High"))
ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, 
                                    levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
# Filter [ Source: ADDM ], including only two clomuns for SLR:
# Dependent variable: Prevalence
# independent variable: Year
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'ADDM', select = c(Prevalence, Year))
#
dim(ASD_State_4_SLR)
head(ASD_State_4_SLR)
```

---


**SLR Workshop Task: <span style="color:blue">1. a. Graph the data in a scatterplot to determine if there is a possible linear relationship.</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

---


**SLR Workshop Task: <span style="color:blue">2. b. Compute and interpret the linear correlation coefficient, r.</span>**


Compute correlaion coefficient

```{r}
cor(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

Apply correlation test (two tail: != 0)

```{r}
cor.test(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
```

Apply correlation test (one tail: > 0)

```{r}
cor.test(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence, alternative = "greater")
```

---


**SLR Workshop Task: <span style="color:blue">3. c. Determine the regression equation for the data.</span>**

```{r}
fit_model = lm(formula = Prevalence ~ Year, data = ASD_State_4_SLR)
print(fit_model)
```

---


**SLR Workshop Task: <span style="color:blue">4. d. Graph the regression equation and the data points.</span>**

```{r}
plot(ASD_State_4_SLR$Year, ASD_State_4_SLR$Prevalence)
abline(fit_model, col="blue", lwd=2)
```

---


**SLR Workshop Task: <span style="color:blue">5. e. Identify potential influential observations (outliers).</span>**

```{r}
# library(repr)
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=6)
par(mfrow=c(2, 2)) 
plot(fit_model)
par(mfrow=c(1, 1))
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* Based on **Residual vs Leverage** chart, there seems no potential influential observations (outliers)



---


**SLR Workshop Task: <span style="color:blue">6. f. At the 5% significance level, do the data provide sufficient evidence to conclude that the slope of the population regression line is not 0 and, hence, that [ Year ] is useful as a predictor of ASD [ Prevalence ]?</span>**

```{r}
summary(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice:**

2. F-test's p-value is 4.13e-15, which is smaller than 0.05, thus above 95% confidence.


---


**SLR Workshop Task: <span style="color:blue">7. g.	Obtain the residuals and create a residual plot. Decide whether it is reasonable to consider that the assumptions for regression analysis are met by the variables in questions.</span>**

```{r}
# library(repr)
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=6)
par(mfrow=c(2, 2)) 
plot(fit_model)
par(mfrow=c(1, 1))
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* Based on **Residual vs Fitted, Sacle-Location, and Normal Q-Q** charts, the residuals (vs fitted) are following linear assumption, with slightly "fan-shape" at larger Year values (Heteroscedasticity). https://statisticsbyjim.com/regression/heteroscedasticity-regression/

* We are to explore polynomial regression method for this issue later.


---


**SLR Workshop Task: <span style="color:blue">8. h.	Compute and interpret the coefficient of determination, $R^2$.</span>**

```{r}
summary(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice:**

* $R^2$ is  0.5219

* Adjusted $R^2$ is  0.5162


---


**SLR Workshop Task: <span style="color:blue">9. i.	Find the predicted ASD Prevalence of future Year.</span>**

```{r}
future_year = 2025
newdata = data.frame(Year = future_year) 
predict(fit_model,newdata)
#
cat("Predicted ASD Prevalence of Year [", future_year, "] is", round(predict(fit_model,newdata), 1), "per 1,000 Children")

```

---


**SLR Workshop Task: <span style="color:blue">10. j.	Determine a 95% confidence interval for the predicted ASD Prevalence.</span>**

```{r}
predict(fit_model, newdata, interval = "predict")
```

```{r}
cat("\nPredicted ASD Prevalence of Year [", future_year, "] (95% Upper CI) is", 
    round(predict(fit_model,newdata, interval = "predict")[3], 1), "per 1,000 Children")

cat("\nPredicted ASD Prevalence of Year [", future_year, "] (95% Lower CI) is", 
    round(predict(fit_model,newdata, interval = "predict")[2], 1), "per 1,000 Children")

```

---


<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        Quiz:
    </h3>
    <p>
        Create Prevalence ~ Year SLR model for Data Source: SPED
    </p>
</div>

```{r}
# Write your code below and press Shift+Enter to execute 

```

Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'SPED', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'NSCH', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, Source_UC == 'MEDI', select = c(Prevalence, Year))
ASD_State_4_SLR = subset(ASD_State, select = c(Prevalence, Year))

-->


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Multiple Linear Regression (MLR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Multiple Linear Regression (MLR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value)

3. c.	Visualize Data and trends

4. d.	Compute correlation between variables and apply multiple regression.

5. e.	Check multicollinearity, then how to remove multicollinearity.

6. f.	How is your ﬁnal model looks like?



**MLR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
# ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
# ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
# ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
# ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
names(ASD_State)
```

```{r}
# Filter to include relevant clomuns for MLR:
# Dependent variable: Prevalence
# independent variable: Let's include all at the moment
ASD_State_4_MLR = ASD_State
#
dim(ASD_State_4_MLR)
head(ASD_State_4_MLR)
```

---


**MLR Workshop Task: <span style="color:blue">2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value).</span>**

```{r}
summary(ASD_State_4_MLR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_MLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_MLR, 2, function(col_x)sum(is.na(col_x))))
```

```{r}
dim(ASD_State_4_MLR)
```

```{r}
#Get all the column variables which contains missing value 
NA_Column_Names <- names(ASD_State_4_MLR[0, colSums(is.na(ASD_State_4_MLR)) > 0])
#
NA_Column_Names
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% NA_Column_Names)]
#
head(ASD_State_4_MLR)
```

**No missing values, as they have been handled earlier. <span style="color:blue">Hurrah!</span>**

**But some varialbe contains <span style="color:blue">"leaky"</span> information, which can be used to directly calculate the dependent variable: Prevalence. This won't happen in real world scenario, thus they need to be removed.**

```{r}
cbind(names(ASD_State_4_MLR), c(1:length(names(ASD_State_4_MLR))))
```

```{r}
Leaky_Column_Names = c('Lower.CI', 'Upper.CI', 'Numerator_ASD', 'Numerator_NonASD', 'Proportion', 
                       'Chi_Wilson_Corrected_Lower.CI', 'Chi_Wilson_Corrected_Upper.CI', 
                       'Prevalence_Risk2', 'Prevalence_Risk4')
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% Leaky_Column_Names)]
#
head(ASD_State_4_MLR)
```

**Remove redundant/duplicate variables (aliased coefficients), retaining one for each type of information is enough:**

https://en.wikipedia.org/wiki/Multicollinearity

https://stats.stackexchange.com/questions/112442/what-are-aliased-coefficients

```{r}
Redundant_Column_Names = c('State', 'Source_Full1', 'State_Full1', 'State_Region', 'Source_UC', 'Source_Full3', 'Year_Factor')
```

```{r}
# Remove these columns from dataframe
ASD_State_4_MLR <- ASD_State_4_MLR[ , !(names(ASD_State_4_MLR) %in% Redundant_Column_Names)]
#
head(ASD_State_4_MLR)
```

---


**MLR Workshop Task: <span style="color:blue">3. c.	Visualize the data to gain insights</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_MLR$Year, ASD_State_4_MLR$Prevalence)
```

```{r}
plot(as.factor(ASD_State_4_MLR$Year), ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$Denominator, ASD_State_4_MLR$Prevalence)
```

```{r}
# To use bin() function
# https://www.rdocumentation.org/packages/OneR/versions/2.2/topics/bin
if(!require(OneR)){install.packages("OneR")}
library('OneR')

# Bin 'Denominator'
plot(bin(ASD_State_4_MLR$Denominator, nbins = 10), ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$Source, ASD_State_4_MLR$Prevalence)
```

```{r}
plot(ASD_State_4_MLR$State_Full2, ASD_State_4_MLR$Prevalence)
```

---


**MLR Workshop Task: <span style="color:blue">4. d.	Compute correlation between variables and apply multiple regression.</span>**


Recode categorical variable to dummy (numeric) variable using one-hot encoding:

```{r}
# To use select_if() function
if(!require(dplyr)){install.packages("dplyr")}
library("dplyr")

summary(select_if(ASD_State_4_MLR, is.numeric))
```

```{r}
correlation = cor(select_if(ASD_State_4_MLR, is.numeric))
correlation
```

```{r}
# Variable's correlation against target dependent variable:
correlation[, 2]
```

```{r}
if(!require(corrplot)){install.packages("corrplot")}
library("corrplot")
corrplot(correlation, tl.col="black", tl.pos = "lt")
```

```{r}
str(ASD_State_4_MLR)
```

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model = lm(Prevalence ~ . - State_Full2, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.6575
    </p>
</div>


```{r}
# To build (US. State level) ASD Prevalence predictive model for specific state's prevalence:
# In situations that we shall know the US. State name. (A state name is required during prediciton.)
fit_model = lm(Prevalence ~ . , data = ASD_State_4_MLR) # "~." means all other variables, including factors
#
summary(fit_model)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7697
    </p>
</div>



---


**MLR Workshop Task: <span style="color:blue">5. e.	Check multicollinearity, then how to remove multicollinearity.</span>**


< Detection of multicollinearity >

Some authors have suggested a formal detection-tolerance or the variance inflation factor (VIF) for multicollinearity. <span style="color:blue">A VIF of 5 or 10 and above</span> indicates a multicollinearity problem.

```{r}
# To use select_if() function
if(!require(car)){install.packages("car")}
library("car")
```

```{r}
vif(fit_model)
```

**<span style="color:blue">[ Tips ]</span> We notice VIF of Denominator and State_Full2 are high.** Let's exclude them one at a time.


**Retain: State; Remove: Denominator then re-build model:**

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model_with_State = lm(Prevalence ~ . - Denominator, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model_with_State)
```

```{r}
vif(fit_model_with_State)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7662
    </p>
</div>



---


**Retain: Denominator; Remove: State; then re-build model:**

```{r}
# To build (National level) ASD Prevalence predictive model for all state's:
# In situations that we won't know the US. State name, we can also fit a model without State name/code:
fit_model_with_Denominator = lm(Prevalence ~ . - State_Full2, data = ASD_State_4_MLR) # Exclude a variable using: "- variable"
#
summary(fit_model_with_Denominator)
```

```{r}
vif(fit_model_with_Denominator)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.6575
    </p>
</div>



---


**MLR Workshop Task: <span style="color:blue">6. f.	How is your ﬁnal model looks like?</span>**

<!-- #region -->
* During prediction, if US. State name will be known, then the **fit_model_with_State** can be better because it has higher $R^2$ value.


* During prediction, if US. State name will NOT be known,  then the **fit_model_with_Denominator** can be adopted because it doesn't require state name as input for prediciton.

<!-- #endregion -->

**MLR Prediciton 1**

Let's use **fit_model_with_State** to predict CA-California ASD Prevalence of Year 2016 if ADDM would have conducted a survey

```{r}
newdata = ASD_State_4_MLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 50000
newdata$Year = 2016
newdata$Source = "addm"
#newdata$State_Full2 = "CA-California"
newdata$State_Full2 = "AZ-Arizona"

newdata
```

```{r}
predict(fit_model_with_State, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model_with_State, newdata), 1), "per 1,000 Children")
```

**MLR Prediciton 2**

Let's use **fit_model_with_Denominator** to predict National level ASD Prevalence of Year 2016 if ADDM would have conducted a survey

```{r}
predict(fit_model_with_Denominator, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model_with_Denominator, newdata), 1), "per 1,000 Children")
```

**MLR Prediciton 2**

Let's use **fit_model** to predict FL-Florida State level ASD Prevalence of Year 2025 if SPED will conduct a record review/survey of 2,600,000 children.

```{r}
newdata = ASD_State_4_MLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 2600000
newdata$Year = 2025
newdata$Source = "sped"
newdata$State_Full2 = "FL-Florida"

newdata
```

```{r}
predict(fit_model, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence is", round(predict(fit_model, newdata), 1), "per 1,000 Children")
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Polynomial (Linear) Regression (PLR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Polynomial (Linear) Regression (PLR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value)

3. c.	Visualize Data and trends

4. d.	Compute correlation between variables and apply multiple regression.

5. e.	Multiple polynomial regression.



**PLR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
names(ASD_State)
```

```{r}
# Filter [ Source: SPED ], including only two clomuns for SLR:
# Dependent variable: Prevalence
# independent variable: Year
# ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'MN-Minnesota', select = c(Prevalence, Year))
# ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'MS-Mississippi', select = c(Prevalence, Year))
ASD_State_4_PLR = subset(ASD_State, Source_UC == 'SPED' & State_Full2 == 'FL-Florida', select = c(Prevalence, Year))
#
dim(ASD_State_4_PLR)
head(ASD_State_4_PLR)
```

---


**PLR Workshop Task: <span style="color:blue">2. b.	Discover and visualize the data to gain insights (Is there missing Value in the dataframe, then how to deal with the missing value).</span>**

```{r}
summary(ASD_State_4_PLR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_PLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_PLR, 2, function(col_x)sum(is.na(col_x))))
```

**No missing values**


---


**PLR Workshop Task: <span style="color:blue">3. c.	Visualize the data to gain insights</span>**

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=4)
```

```{r}
plot(ASD_State_4_PLR$Year, ASD_State_4_PLR$Prevalence)
```

---


**PLR Workshop Task: <span style="color:blue">4. d.	Compute correlation between variables and apply multiple regression.</span>**


Recode categorical variable to dummy (numeric) variable using one-hot encoding:

```{r}
# To use select_if() function
if(!require(dplyr)){install.packages("dplyr")}
library("dplyr")

summary(select_if(ASD_State_4_PLR, is.numeric))
```

```{r}
correlation = cor(select_if(ASD_State_4_PLR, is.numeric))
correlation
```

```{r}
# Variable's correlation against target dependent variable:
correlation[, 1]
```

```{r}
str(ASD_State_4_PLR)
```

```{r}
# SLR
fit_model_SLR = lm(Prevalence ~ Year , data = ASD_State_4_PLR)
#
summary(fit_model_SLR)
```

```{r}
plot(fit_model_SLR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.958
    </p>
</div>


```{r}
# PLR (quadratic)
fit_model_PLR = lm(Prevalence ~ Year + I(Year^2), data = ASD_State_4_PLR)
#
summary(fit_model_PLR)
```

**Abount I() function:** https://stackoverflow.com/questions/8055508/in-r-formulas-why-do-i-have-to-use-the-i-function-on-power-terms-like-y-i


```{r}
plot(fit_model_PLR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.9981
    </p>
</div>



**Visualise the difference between SLR & PLR:**

```{r}
plot(ASD_State_4_PLR$Year, ASD_State_4_PLR$Prevalence)
# add SLR line
lines(ASD_State_4_PLR$Year, predict(fit_model_SLR, ASD_State_4_PLR), col="blue", lwd=2) # or # abline(fit_model_SLR, col="blue", lwd=2)
# add PLR line
lines(ASD_State_4_PLR$Year, predict(fit_model_PLR, ASD_State_4_PLR), col="orange", lwd=2) 
```

---


**PLR Prediciton**


```{r}
newdata = ASD_State_4_PLR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Year = 2025

newdata
```

```{r}
predict(fit_model_PLR, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence of Year [", newdata$Year, "] is", round(predict(fit_model_PLR, newdata), 1), "per 1,000 Children")

```

---


**Multiple PLR Workshop Task: <span style="color:blue">5. e.	Multiple polynomial regression (MPR).</span>** (Enhance MLR by adding higher order transformed variables.)


**Resuse MLR data: <span style="color:blue">ASD_State_4_MLR</span>** Cop to new dataframe: ASD_State_4_MPR

```{r}
ASD_State_4_MPR = ASD_State_4_MLR

dim(ASD_State_4_MPR)

```

```{r}
summary(ASD_State_4_MPR)
```

```{r}
# Check whether each columns got missing value:
lapply(ASD_State_4_MLR, function(col_x)sum(is.na(col_x)))
       
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=3)
barplot(apply(ASD_State_4_MLR, 2, function(col_x)sum(is.na(col_x))))
```

**Build Multiple PLR model: + I(Year^2) + I(log(Denominator)**

```{r}
fit_model_MPR = lm(Prevalence ~ . + I(Year^2) + I(log(Denominator)), data = ASD_State_4_MPR) # "~." means all other variables, including factors
#
summary(fit_model_MPR)
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        Adjusted $R^2$ = 0.7884
    </p>
</div>



**Mutiple PLR Prediciton**

```{r}
# Copy datastructure
newdata = subset(ASD_State_4_MPR, ASD_State_4_MPR$Year == 2016 &
                            ASD_State_4_MPR$State_Full2 == 'FL-Florida' & 
                            ASD_State_4_MPR$Source == 'sped')
newdata
```

```{r}
newdata = ASD_State_4_MPR[1,] # Copy datastructure
newdata$Prevalence = NA
newdata$Denominator = 2600000
newdata$Year = 2025
newdata$Source = "sped"
newdata$State_Full2 = "FL-Florida"

newdata
```

```{r}
predict(fit_model_MPR, newdata, interval = "predict")
#
cat("Predicted ASD Prevalence of Year [", newdata$Year, "] is", round(predict(fit_model_MPR,newdata), 1), "per 1,000 Children")

```

<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        Quiz:
    </h3>
    <p>
        Compare predicted ASD prevalence and model $R^2$ between: Multiple Linear Rregression and Multiple Polynomial Rregression.
    </p>
    <p>
        Which prediction result would you use? Provide yor justifications.
    </p>
</div>

```{r}
# Write your code below and press Shift+Enter to execute 

```

Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
# TBD

-->


<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Logistic Regression (LR)</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Logistic Regression (LR) - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Get the data.

2. b.	Logistic regression - Binary Class.

3. c.	Logistic regression - Multi-Class.



**LR Workshop Task: <span style="color:blue">1. a. Get the data.</span>**


**Use Case Data: <span style="color:blue">"../dataset/ADV_ASD_State_R.csv"</span>**


**Read in CSV data, storing as R <span style="color:blue">dataframe</span>**

```{r}
# Read back in above saved file:
# ASD_State <- read.csv("../dataset/ADV_ASD_State_R.csv")
# ASD_State$Year_Factor <- factor(ASD_State$Year_Factor, ordered = TRUE) # Convert Year_Factor to ordered.factor
# ASD_State$Prevalence_Risk2 = factor(ASD_State$Prevalence_Risk2, ordered=TRUE, levels=c("Low", "High"))
# ASD_State$Prevalence_Risk4 = factor(ASD_State$Prevalence_Risk4, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))

```

```{r}
head(ASD_State)
```

```{r}
Column_Names = c("Prevalence_Risk2", "Denominator", "Year", "Source", "State_Full2")
ASD_State_4_LR_Risk2 <- ASD_State[ , (names(ASD_State) %in% Column_Names)]
dim(ASD_State_4_LR_Risk2)
head(ASD_State_4_LR_Risk2)
```

```{r}
Column_Names = c("Prevalence_Risk4", "Denominator", "Year", "Source", "State_Full2")
ASD_State_4_LR_Risk4 <- ASD_State[ , (names(ASD_State) %in% Column_Names)]
dim(ASD_State_4_LR_Risk4)
head(ASD_State_4_LR_Risk4)
```

---


**LR Workshop Task: <span style="color:blue">2. b.	Logistic regression (LR) Binary Class.</span>** (Reuse Multiple Polynomial Model on categorical dependent variable.)

```{r}
table(ASD_State_4_LR_Risk2$Prevalence_Risk2)
barplot(table(ASD_State_4_LR_Risk2$Prevalence_Risk2))
```

```{r}
counts = table(ASD_State_4_LR_Risk2$Prevalence_Risk2, ASD_State_4_LR_Risk2$Source)
counts
barplot(counts,
        main="Prevalence by Data Sources and Risk Levels",
        xlab="Data Sources",
        ylab="Occurrences",
        col=c("white", "lightgrey"),
        legend = rownames(counts), 
        args.legend = list(x = "topleft", bty = "n", cex = 0.85, y.intersp = 4))

```

```{r}
str(ASD_State_4_LR_Risk2)
```

**Build model**

```{r}
# Binary Classification:
fit_model_LR_Risk2 = glm(Prevalence_Risk2 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                         family=binomial(link='logit'), data = ASD_State_4_LR_Risk2)
#
summary(fit_model_LR_Risk2)

```

**Evaluate model**

```{r}
# Likelihood ratio test: significance of the difference between the full model and the null model.
pchisq(fit_model_LR_Risk2$null.deviance - fit_model_LR_Risk2$deviance, 
       fit_model_LR_Risk2$df.null - fit_model_LR_Risk2$df.residual, lower.tail = FALSE)

```

**Check whether above value is very small (the smaller the more significant), e.g. < 0.05.**


< How to perform a Logistic Regression in R > Michy Alice

https://www.r-bloggers.com/how-to-perform-a-logistic-regression-in-r/


```{r}
# null deviance and the residual deviance
anova(fit_model_LR_Risk2, test="Chisq")
```

```{r}
# R^2 equivalent
if(!require(pscl)){install.packages("pscl")}
library("pscl")
```

While no exact equivalent to the $R^2$ of linear regression exists, the **McFadden $R^2$** index can be used to assess the model fit.

```{r}
# R^2 equivalent
pR2(fit_model_LR_Risk2)[4]
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        McFadden $R^2$ = 0.6374
    </p>
</div>



---


**LR Workshop Task: <span style="color:blue">3. c.	Logistic regression (LR) Muti-Class.</span>** (Reuse Multiple Polynomial Model on categorical dependent variable.)

```{r}
table(ASD_State_4_LR_Risk4$Prevalence_Risk4)
barplot(table(ASD_State_4_LR_Risk4$Prevalence_Risk4))
```

```{r}
counts = table(ASD_State_4_LR_Risk4$Prevalence_Risk4, ASD_State_4_LR_Risk4$Source)
counts
barplot(counts,
        main="Prevalence Occurrence by Source and Risk",
        xlab="Data Sources",
        ylab="Occurrences",
        col=c("lightyellow", "orange", "red","darkred"),
        legend = rownames(counts), 
        args.legend = list(x = "topleft", bty = "n", cex = 0.85, y.intersp = 4))

```

**Build model**

```{r}
# multinom function from the nnet package 
if(!require(nnet)){install.packages("nnet")}
library("nnet")
```

```{r}
# Multi-Class Classification:
fit_model_LR_Risk4 = multinom(Prevalence_Risk4 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                     data = ASD_State_4_LR_Risk4, maxit=1000) # maxit https://cran.r-project.org/web/packages/nnet/nnet.pdf

summary(fit_model_LR_Risk4)

```

< MULTINOMIAL LOGISTIC REGRESSION | R DATA ANALYSIS EXAMPLES >

https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/

```{r}
## extract the coefficients from the model and exponentiate
exp(coef(fit_model_LR_Risk4))
# Uncomment below to display all p values:
# paste(exp(coef(fit_model)))
```

```{r}
# Test the significance/importance of each coefficient (check if p values < 0.05)

# z score for coefficients
z <- summary(fit_model_LR_Risk4)$coefficients/summary(fit_model_LR_Risk4)$standard.errors
cat('\n< Talbe of coefficient z scores>')
z

# p value of 2-tailed z test
p <- (1 - pnorm(abs(z), 0, 1)) * 2
cat('\n< Talbe of coefficient p values>')
p
# Uncomment below to display all p values:
# paste(p)
```

While no exact equivalent to the $R^2$ of linear regression exists, the **McFadden $R^2$** index can be used to assess the model fit.

```{r}
# R^2 equivalent
pR2(fit_model_LR_Risk4)[4]
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <p>
        McFadden $R^2$ = 0.6035
    </p>
</div>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Model Evaluation</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Linear Model: Model Evaluation - Workshop Task
    </h3>
</div>



**Workshop Task:**

1. a.	Train/Test Dataset Split
2. b.	Confusion Matrix & Accuracy for Classification
3. c.	K-Fold Cross Validation
4. d.	$R^2$, MSE, RMSE for Regression for Regression


**Model Evaluation Workshop Task: <span style="color:blue">1. a.	Train/Test Dataset Split</span>**

```{r}
if(!require(caTools)){install.packages("caTools")}
library("caTools") 
```

```{r}
# Generate a random number sequence that can be reproduced to check results thru the seed number.
set.seed(88)

# Stratified Random Sampling: split dataset into two sets in predefined proportion (SplitRatio)
# while preserving differnt class ratios of dependent variable. (e.g. Proportion of Low/High)
split <- sample.split(ASD_State_4_LR_Risk2$Prevalence_Risk2, SplitRatio = 0.7)
```

```{r}
# Get training and test data
trainset <- subset(ASD_State_4_LR_Risk2, split == TRUE) 
testset <- subset(ASD_State_4_LR_Risk2, split == FALSE)
```

**Build a binary classification model to predict (categorical) Prevalence Risk Level using Logistic Regression (LR)**

```{r}
# Binary Classification:
fit_model_LR_Risk2 = glm(Prevalence_Risk2 ~ Denominator + Year + Source + State_Full2 + I(Year^2) + I(log(Denominator)), 
                         family=binomial(link='logit'), data = trainset) # data = trainset

summary(fit_model_LR_Risk2)

```

**Model Evaluation Workshop Task: <span style="color:blue">2. b.	Confusion Matrix & Accuracy for Classification</span>**


https://en.wikipedia.org/wiki/Confusion_matrix

```{r}
# Confusion matrix on Trainset
probTrainset <- predict(fit_model_LR_Risk2, type = 'response')
# One way is to use the proportion of High risk in the *Training* data.
threshold2 <- sum(trainset$Prevalence_Risk2 == "High")/length(trainset$Prevalence_Risk2)
cat('Trainset High Risk Threshold = ', threshold2)
# If logistic regression probability > threshold, predict High, else predict Low.
predictTrainset <- ifelse(probTrainset > threshold2, "High", "Low")
# Create a contingency table (Confusion Matrix) with actuals on rows and predictions on columns.
table(trainset$Prevalence_Risk2, predictTrainset)

# Accuracy on Trainset
AccuracyTrain <- mean(predictTrainset == trainset$Prevalence_Risk2) 
cat('Trainset Accuracy = ', AccuracyTrain)
```

```{r}
# Confusion matrix on Testset
probTestset <- predict(fit_model_LR_Risk2, newdata = testset, type = 'response') # newdata = testset
# One way is to use the proportion of High risk in the *Training* data.
cat('Reused Trainset High Risk Threshold = ', threshold2)
# If logistic regression probability > threshold, predict High, else predict Low.
predictTestset <- ifelse(probTestset > threshold2, "High", "Low")
# Create a contingency table (Confusion Matrix) with actuals on rows and predictions on columns.
table(testset$Prevalence_Risk2, predictTestset)

# Accuracy on Trainset
AccuracyTest <- mean(predictTestset == testset$Prevalence_Risk2) 
cat('Testset Accuracy = ', AccuracyTest)
```

**Model Evaluation Workshop Task: <span style="color:blue">3. c.	K-Fold Cross Validation</span>**


### R caret package

The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for:

* data splitting
* pre-processing
* feature selection
* model tuning using resampling
* variable importance estimation

http://topepo.github.io/caret/index.html


```{r}
if(!require(caret)){install.packages("caret")}
library("caret")
```

```{r}
if(!require(e1071)){install.packages("e1071")}
library("e1071")
```

```{r}
# Caret train/test split method:
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_LR_Risk2$Prevalence_Risk2, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_LR_Risk2[caret_idx, ]
caret_testset  = ASD_State_4_LR_Risk2[-caret_idx, ]

#caret_threshold <- sum(caret_trainset$Prevalence_Risk2 == "Low")/length(caret_trainset$Prevalence_Risk2)
#caret_threshold
```

```{r}
# Caret logistic regresion
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)

caret_model_LR_Risk2 = train(form = Prevalence_Risk2 ~ ., data = caret_trainset, 
                             trControl = cv_control, method = "glm", family = "binomial")
#
caret_model_LR_Risk2
```

```{r}
# Get predicted class label
caret_model_LR_Risk2_Pred <- predict(caret_model_LR_Risk2, caret_testset)

# Uncomment below to get class probability
# caret_model_LR_Risk2_Pred <- predict(caret_model_LR_Risk2, caret_testset, type = "prob")

```

https://topepo.github.io/caret/using-your-own-model-in-train.html#Illustration5

```{r}
# CM & Acc
cm_table <- table(as.factor(caret_model_LR_Risk2_Pred), caret_testset$Prevalence_Risk2)
confusionMatrix(cm_table)
```

**Model Evaluation Workshop Task: <span style="color:blue">4. d.	$R^2$, MSE, RMSE for Regression</span>**

```{r}
# Caret train/test split method:
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_MLR$Prevalence, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_MLR[caret_idx, ]
caret_testset  = ASD_State_4_MLR[-caret_idx, ]
```

```{r}
# Look at below plots of train and test, shape of distribution are similar, which means good sampling.
par(mfrow=c(1, 2)) 
plot(density(caret_trainset$Prevalence))
plot(density(caret_testset$Prevalence))
par(mfrow=c(1, 1))
```

**Build a regression model to predict (numeric) Prevalanece using Multiple Linear Regression (MLR)**

```{r}
if(!require(elasticnet)){install.packages("elasticnet")}
library("elasticnet")
```

```{r}
# Caret MLR regresion
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)
#
caret_model_MLR <- train(Prevalence ~ ., data = caret_trainset, trControl = cv_control, method = "lm") 
#
caret_model_MLR
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=8)
ggplot(varImp(caret_model_MLR))
# plot(varImp(caret_model_MLR))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Linear Model: Prevent Overfitting by Regularization Methods</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Linear Model: Prevent Overfitting by Regularization Methods - L1 Lasso Regression & L2 Ridge regression
    </h3>
</div>



https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c

* L1 Lasso Regression (Least Absolute Shrinkage and Selection Operator) adds “absolute value of magnitude” of coefficient as penalty term to the loss function.

* L2 Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function. 

The key difference between these techniques is that L1 Lasso shrinks the less important feature’s coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.



https://towardsdatascience.com/create-predictive-models-in-r-with-caret-12baf9941236


**Enhanced MLR using Regularization: L1 Lasso**

```{r}
if(!require(elasticnet)){install.packages("elasticnet")}
library("elasticnet")
```

```{r}
# Caret MLR with Regularization
# possible method: boot", "boot632", "cv", "repeatedcv", "LOOCV", "LGOCV"
cv_control <- trainControl(method = "repeatedcv",   
                           number = 10,     # number of folds
                           repeats = 5)    # repeated N times

caret_model_MLR_L1 <- train(Prevalence ~ .,
               data = caret_trainset,
               method = "lasso",  # Try using "ridge"
               trControl = cv_control,
               preProcess = c('scale', 'center'))  # Auto pre-process data
#
caret_model_MLR_L1
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=2)
ggplot(varImp(caret_model_MLR_L1))
# plot(varImp(caret_model_MLR_L1))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR_L1, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

---


**Enhanced MLR using Regularization: L2 Ridge**

```{r}
# Caret MLR with Regularization
# possible method: boot", "boot632", "cv", "repeatedcv", "LOOCV", "LGOCV"
cv_control <- trainControl(method = "repeatedcv",   
                           number = 10,     # number of folds
                           repeats = 5)    # repeated N times

caret_model_MLR_L2 <- train(Prevalence ~ .,
               data = caret_trainset,
               method = "ridge",  # Try using "lasso"
               trControl = cv_control,
               preProcess = c('scale', 'center'))  # Auto pre-process data
#
caret_model_MLR_L2
```

```{r}
# Adjust in-line plot size to M x N
options(repr.plot.width=8, repr.plot.height=2)
ggplot(varImp(caret_model_MLR_L2))
# plot(varImp(caret_model_MLR_L2))
```

```{r}
caret_model_MLR_Pred <- predict(caret_model_MLR_L2, caret_testset)
head(caret_model_MLR_Pred)
```

```{r}
# MSE
mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2)
```

```{r}
# RMSE
sqrt(mean((caret_testset$Prevalence - caret_model_MLR_Pred)^2))
```

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Workshop Submission</span>



<div class="alert alert-danger alertdanger" style="margin-top: 20px">
    <h3>
        What to submit?
    </h3>
    <p>
        Create predictive model for Multi Class Classification of ASD Prevalence Risk Level (Low, Medium, High, Very High) using Caret package's multinom logistic regression algorithm.
    </p>
</div>


References:

https://daviddalpiaz.github.io/r4sl/the-caret-package.html

http://topepo.github.io/caret/index.html

https://cran.r-project.org/web/packages/caret/caret.pdf


```{r}
# Code example of multinomial logistic regresion using Iris flower dataset
iris[c(1:3, 51:53, 101:103), ]
summary(iris)
iris_model = train(Species ~ ., data = iris, method = "multinom", 
                     trControl = trainControl(method = "cv", number = 5), trace = FALSE)
iris_model
```

```{r}
# Write your code below and press Shift+Enter to execute 

```

<!-- #region -->
Double-click <b>here</b> for the solution.

<!-- The answer is below:

# Write your code below and press Shift+Enter to execute 
#
# < Multi Class Classification of ASD Prevalence Risk Level >
#
# ----------------------------------
# Caret train/test split method:
# ----------------------------------
set.seed(88)
caret_idx = createDataPartition(ASD_State_4_LR_Risk4$Prevalence_Risk4, p = 0.85, list = FALSE)
caret_trainset = ASD_State_4_LR_Risk4[caret_idx, ]
caret_testset  = ASD_State_4_LR_Risk4[-caret_idx, ]

# ----------------------------------
# Caret multinomial logistic regresion
# ----------------------------------
# Cross Validation setting
set.seed(88)
cv_control = trainControl(method = "cv", number = 5)
# Train model
caret_model_LR_Risk4 = train(form = Prevalence_Risk4 ~ ., data = caret_trainset, 
                             trControl = cv_control, method = "multinom", trace = FALSE)
#                             trControl = cv_control, method = "glm", family = "binomial")

# ----------------------------------
# Summary of model
# ----------------------------------
caret_model_LR_Risk4

# ----------------------------------
# Get predicted class label
# ----------------------------------
caret_model_LR_Risk4_Pred <- predict(caret_model_LR_Risk4, caret_testset)
head(caret_model_LR_Risk4_Pred)

# ----------------------------------
# Get predicted class probability
# ----------------------------------
caret_model_LR_Risk4_Pred_Prob <- predict(caret_model_LR_Risk4, caret_testset, type = "prob")
head(caret_model_LR_Risk4_Pred_Prob)

# ----------------------------------
# CM & Acc
# ----------------------------------
cm_table <- table(as.factor(caret_model_LR_Risk4_Pred), caret_testset$Prevalence_Risk4)
confusionMatrix(cm_table)


-->
<!-- #endregion -->

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




### Excellent! You have completed the workshop notebook!


**Connect with the author:**

This notebook was written by [GU Zhan (Sam)](https://sg.linkedin.com/in/zhan-gu-27a82823 "GU Zhan (Sam)").

[Sam](https://www.iss.nus.edu.sg/about-us/staff/detail/201/GU%20Zhan "GU Zhan (Sam)") is currently a lecturer in [Institute of Systems Science](https://www.iss.nus.edu.sg/ "NUS-ISS") in [National University of Singapore](http://www.nus.edu.sg/ "NUS"). He devotes himself into pedagogy & andragogy, and is very passionate in inspiring next generation of artificial intelligence lovers and leaders.



Copyright &copy; 2020 GU Zhan

This notebook and its source code are released under the terms of the [MIT License](https://en.wikipedia.org/wiki/MIT_License "Copyright (c) 2020 GU ZHAN").

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="">
         <img src="" width="750" align="center">
    </a>
</div>




## <span style="color:blue">Appendices</span>



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <h3>
    Interactive workshops: < Learning R inside R > using swirl() (in R/RStudio)
    </h3>
</div>



https://github.com/telescopeuser/S-SB-Workshop



<div class="alert alert-block alert-info" style="margin-top: 20px">
    <a href="https://github.com/dd-consulting">
         <img src="../reference/GZ_logo.png" width="60" align="right">
        https://github.com/dd-consulting
    </a>
</div>



---
